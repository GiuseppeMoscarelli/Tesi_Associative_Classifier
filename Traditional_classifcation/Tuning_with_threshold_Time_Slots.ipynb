{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collaborative-convert",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from math import sin, cos, sqrt, atan2, radians \n",
    "from sklearn import tree, svm, linear_model, ensemble, neighbors, naive_bayes \n",
    "import dateutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impaired-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_path = Path('../filtered_status.csv')\n",
    "stations_path = Path('../station.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proud-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df = pd.read_csv(status_path, parse_dates=['time'])\n",
    "stations_df = pd.read_csv(stations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grateful-family",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>bikes_available</th>\n",
       "      <th>docks_available</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:06:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:07:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:08:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:09:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:10:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977905</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:55:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977906</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:56:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977907</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:57:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977908</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:58:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977909</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:59:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71977910 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          station_id  bikes_available  docks_available                time\n",
       "0                  2                2               25 2013-08-29 12:06:01\n",
       "1                  2                2               25 2013-08-29 12:07:01\n",
       "2                  2                2               25 2013-08-29 12:08:01\n",
       "3                  2                2               25 2013-08-29 12:09:01\n",
       "4                  2                2               25 2013-08-29 12:10:01\n",
       "...              ...              ...              ...                 ...\n",
       "71977905          84                8                7 2015-08-31 23:55:02\n",
       "71977906          84                8                7 2015-08-31 23:56:01\n",
       "71977907          84                8                7 2015-08-31 23:57:02\n",
       "71977908          84                8                7 2015-08-31 23:58:02\n",
       "71977909          84                8                7 2015-08-31 23:59:02\n",
       "\n",
       "[71977910 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broke-millennium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dock_count</th>\n",
       "      <th>city</th>\n",
       "      <th>installation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>San Jose Diridon Caltrain Station</td>\n",
       "      <td>37.329732</td>\n",
       "      <td>-121.901782</td>\n",
       "      <td>27</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/6/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>San Jose Civic Center</td>\n",
       "      <td>37.330698</td>\n",
       "      <td>-121.888979</td>\n",
       "      <td>15</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/5/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Santa Clara at Almaden</td>\n",
       "      <td>37.333988</td>\n",
       "      <td>-121.894902</td>\n",
       "      <td>11</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/6/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Adobe on Almaden</td>\n",
       "      <td>37.331415</td>\n",
       "      <td>-121.893200</td>\n",
       "      <td>19</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/5/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>San Pedro Square</td>\n",
       "      <td>37.336721</td>\n",
       "      <td>-121.894074</td>\n",
       "      <td>15</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/7/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>77</td>\n",
       "      <td>Market at Sansome</td>\n",
       "      <td>37.789625</td>\n",
       "      <td>-122.400811</td>\n",
       "      <td>27</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>8/25/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>80</td>\n",
       "      <td>Santa Clara County Civic Center</td>\n",
       "      <td>37.352601</td>\n",
       "      <td>-121.905733</td>\n",
       "      <td>15</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>12/31/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>82</td>\n",
       "      <td>Broadway St at Battery St</td>\n",
       "      <td>37.798541</td>\n",
       "      <td>-122.400862</td>\n",
       "      <td>15</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1/22/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>83</td>\n",
       "      <td>Mezes Park</td>\n",
       "      <td>37.491269</td>\n",
       "      <td>-122.236234</td>\n",
       "      <td>15</td>\n",
       "      <td>Redwood City</td>\n",
       "      <td>2/20/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>84</td>\n",
       "      <td>Ryland Park</td>\n",
       "      <td>37.342725</td>\n",
       "      <td>-121.895617</td>\n",
       "      <td>15</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>4/9/2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                               name        lat        long  dock_count  \\\n",
       "0    2  San Jose Diridon Caltrain Station  37.329732 -121.901782          27   \n",
       "1    3              San Jose Civic Center  37.330698 -121.888979          15   \n",
       "2    4             Santa Clara at Almaden  37.333988 -121.894902          11   \n",
       "3    5                   Adobe on Almaden  37.331415 -121.893200          19   \n",
       "4    6                   San Pedro Square  37.336721 -121.894074          15   \n",
       "..  ..                                ...        ...         ...         ...   \n",
       "65  77                  Market at Sansome  37.789625 -122.400811          27   \n",
       "66  80    Santa Clara County Civic Center  37.352601 -121.905733          15   \n",
       "67  82          Broadway St at Battery St  37.798541 -122.400862          15   \n",
       "68  83                         Mezes Park  37.491269 -122.236234          15   \n",
       "69  84                        Ryland Park  37.342725 -121.895617          15   \n",
       "\n",
       "             city installation_date  \n",
       "0        San Jose          8/6/2013  \n",
       "1        San Jose          8/5/2013  \n",
       "2        San Jose          8/6/2013  \n",
       "3        San Jose          8/5/2013  \n",
       "4        San Jose          8/7/2013  \n",
       "..            ...               ...  \n",
       "65  San Francisco         8/25/2013  \n",
       "66       San Jose        12/31/2013  \n",
       "67  San Francisco         1/22/2014  \n",
       "68   Redwood City         2/20/2014  \n",
       "69       San Jose          4/9/2014  \n",
       "\n",
       "[70 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-district",
   "metadata": {},
   "source": [
    "## Ottengo gli id delle stazioni per ogni città diversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-zealand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['San Jose', 'Redwood City', 'Mountain View', 'Palo Alto',\n",
       "       'San Francisco'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = stations_df['city'].unique()\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "every-baghdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'San Jose': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 16, 80, 84]),\n",
       " 'Redwood City': array([21, 22, 23, 24, 25, 26, 83]),\n",
       " 'Mountain View': array([27, 28, 29, 30, 31, 32, 33]),\n",
       " 'Palo Alto': array([34, 35, 36, 37, 38]),\n",
       " 'San Francisco': array([41, 42, 45, 46, 47, 48, 49, 50, 51, 39, 54, 55, 56, 57, 58, 59, 60,\n",
       "        61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
       "        82])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_stations = {}\n",
    "\n",
    "for city in cities:\n",
    "    city_stations[city] = stations_df[stations_df['city'] == city]['id'].unique()\n",
    "\n",
    "city_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-therapy",
   "metadata": {},
   "source": [
    "## Prendo in cosiderazione solo gli id delle stazioni appartenenti alla città di San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crazy-representative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 42, 45, 46, 47, 48, 49, 50, 51, 39, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
       "       82])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "San_Fancisco_stations = city_stations[\"San Francisco\"]\n",
    "San_Fancisco_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "isolated-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval=30\n",
    "window_width = 5\n",
    "\n",
    "time_slots = [\n",
    "    \"0-6\", \n",
    "    \"6-10\", \n",
    "    \"10-14\", \n",
    "    \"14-17\", \n",
    "    \"17-20\", \n",
    "    \"20-24\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-tomato",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cooperative-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'DecisionTree': tree.DecisionTreeClassifier(random_state=42),   \n",
    "#     'SVC': svm.SVC(),\n",
    "#     'LogisticRegression': linear_model.LogisticRegression(random_state=42, solver='liblinear', max_iter=1000),\n",
    "#     'NaiveBayes': naive_bayes.GaussianNB(),\n",
    "#     'RandomForest': ensemble.RandomForestClassifier(random_state=42, max_features='sqrt'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-cyprus",
   "metadata": {},
   "source": [
    "Effettuo il finetuning dei modelli tramite la grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_parameters = {\n",
    "    'max_depth': list(range(2, 7)),\n",
    "    'min_samples_split': list(range(2, 7)),\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "SVC_parameters = {\n",
    "    'C': [0.1, 1, 100],\n",
    "    'gamma': [0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "logistic_regression_parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1, 0.1, 0.01, 0.001],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "random_forest_parameters = {\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth': list(range(0, 5)), \n",
    "    'min_samples_split': list(range(0, 5)), \n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "naive_bayes_parameters = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "classifiers_parameters = {\n",
    "  'DecisionTree': decision_tree_parameters,\n",
    "  'SVC': SVC_parameters,\n",
    "  'LogisticRegression': logistic_regression_parameters,\n",
    "  'RandomForest': random_forest_parameters,\n",
    "  'NaiveBayes': naive_bayes_parameters\n",
    "}\n",
    "\n",
    "tuned_classifiers = {\n",
    "    'DecisionTree': [],\n",
    "    'SVC': [],\n",
    "    'LogisticRegression': [],\n",
    "    'RandomForest': [],\n",
    "    'KNN': []\n",
    "}\n",
    "\n",
    "\n",
    "for slot in time_slots:\n",
    "    print(f\"---- TIME SLOT {slot} ----\\n\")\n",
    "    for reference_station in San_Fancisco_stations:\n",
    "        train_df = pd.read_csv(f\"./datasets/{interval}_{window_width}/Train_test_with_time/station{reference_station}_train.csv\")\n",
    "\n",
    "        time_slot_train_df = train_df.set_index(\"time\", drop=True)\n",
    "        time_slot_train_df.index=pd.to_datetime(time_slot_train_df.index)\n",
    "        start_time= slot.split('-')[0]\n",
    "        end_time = slot.split('-')[1]\n",
    "        if end_time != '24':       \n",
    "            time_slot_train_df = time_slot_train_df.between_time(f'{start_time}:00', f'{end_time}:00')\n",
    "        else:\n",
    "            time_slot_train_df = time_slot_train_df.between_time(f'{start_time}:00', '23:59')\n",
    "\n",
    "        y = time_slot_train_df['status']\n",
    "        X = time_slot_train_df.drop(columns=['status'])\n",
    "        X = X.reset_index().drop(columns=['time'])\n",
    "        \n",
    "        for scoring in ['accuracy', 'recall', 'precision', 'f1_score']:\n",
    "            for classifier in classifiers.keys():\n",
    "                print(f\"Classifier: {classifier}\" )   \n",
    "\n",
    "                clf = classifiers[classifier]\n",
    "                parametrers = classifiers_parameters[classifier]\n",
    "\n",
    "                #I segunti controlli sono necessari in quanto richiamo, precisione e \n",
    "                # f1score hanno necessità di conoscere quale sia la classe positiva (QP)\n",
    "                if scoring == \"recall\":\n",
    "                    scorer = make_scorer(recall_score, pos_label=\"QP\")\n",
    "                elif scoring == \"precision\":\n",
    "                    scorer = make_scorer(precision_score, pos_label=\"QP\")\n",
    "                elif scoring == \"f1_score\":\n",
    "                    scorer = make_scorer(f1_score, pos_label=\"QP\")\n",
    "                else:\n",
    "                    scorer = scoring\n",
    "\n",
    "                #Nel caso di logist regression utilizzo la randomizedSearchCV, in quanto più veloce rispetto alla gridSearchCV\n",
    "                if classifier == 'LogisticRegression':\n",
    "                    search_result = RandomizedSearchCV(clf, parametrers, scoring=scorer, random_state=42, n_iter=5, n_jobs=-1)\n",
    "                else:\n",
    "                    search_result = GridSearchCV(clf, parametrers, scoring=scorer, cv=3, n_jobs=-1)\n",
    "\n",
    "                fit_result = search_result.fit(X, y)\n",
    "                params = fit_result.best_params_\n",
    "\n",
    "                print(\"-\"*10)\n",
    "                print(f\"Best parameters for classifier {classifier} for the station {reference_station} using the scoring {scoring}: \")\n",
    "                print(params)\n",
    "                print()\n",
    "                print()\n",
    "\n",
    "                tuned_clf = search_result.best_estimator_\n",
    "\n",
    "                #salvo il modello dopo il fine tuning\n",
    "                if (Path.cwd() / f'tuned_models_time_slots/{scoring}/{classifier}/{interval}_{window_width}/{slot}').exists() == False:\n",
    "                    os.makedirs(f\"./tuned_models_time_slots/{scoring}/{classifier}/{interval}_{window_width}/{slot}\")\n",
    "                dump(tuned_clf, f'./tuned_models_time_slots/{scoring}/{classifier}/{interval}_{window_width}/{slot}/station{reference_station}_tuned_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-emerald",
   "metadata": {},
   "source": [
    "## Testing dei fine tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "noticed-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_table = {}\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95]\n",
    "\n",
    "for slot in time_slots:\n",
    "    for scoring in [\"precision\"]:\n",
    "        result_matrix = []\n",
    "        for classifier in classifiers.keys():\n",
    "            for threshold in thresholds:\n",
    "                file = open(f'test_results/tuned_classifiers_with_threshold_time_slots/results_{slot}_{classifier}_{scoring}_{interval}_{window_width}_({int(threshold*100)}%).txt', \"w\")\n",
    "#                 file = open(f'test_results/tuned_classifiers_with_threshold_time_slots(1)/results_{slot}_{classifier}_{scoring}_{interval}_{window_width}_({int(threshold*100)}%).txt', \"w\")\n",
    "\n",
    "                file.write(f'TESING RESULTS FOR {classifier} CLASSIFIER WITH THRESHOLD {int(threshold*100)}%:\\n\\n')\n",
    "                tot_fp = 0\n",
    "                tot_tp = 0\n",
    "                tot_fn = 0\n",
    "                tot_tn = 0\n",
    "\n",
    "                for station_id in San_Fancisco_stations:\n",
    "#                     print (f\"------------- {station_id}\")\n",
    "                    # Modelli allenati secondo le diverse fasce orarie\n",
    "                    model = load(f'./tuned_models_time_slots/{scoring}/{classifier}/{interval}_{window_width}/{slot}/station{station_id}_tuned_model.joblib')\n",
    "                    \n",
    "                    # Modelli allenati su tutto il training set\n",
    "#                     model = load(f'./tuned_models/{scoring}/{classifier}/{interval}_{window_width}/station{station_id}_tuned_model.joblib')\n",
    "                    \n",
    "                    test_df = pd.read_csv(f'./datasets/{interval}_{window_width}/Train_test_with_time/station{station_id}_test.csv')\n",
    "                       \n",
    "                    time_slot_test_df = test_df.set_index(\"time\", drop=True)\n",
    "                    time_slot_test_df.index=pd.to_datetime(time_slot_test_df.index)\n",
    "                    start_time= slot.split('-')[0]\n",
    "                    end_time = slot.split('-')[1]\n",
    "                    if end_time != '24':       \n",
    "                        time_slot_test_df = time_slot_test_df.between_time(f'{start_time}:00', f'{end_time}:00')\n",
    "                    else:\n",
    "                        time_slot_test_df = time_slot_test_df.between_time(f'{start_time}:00', '23:59')\n",
    "\n",
    "                    y_test = time_slot_test_df['status']\n",
    "                    X_test = time_slot_test_df.drop(columns=['status']) \n",
    "                    X_test = X_test.reset_index().drop(columns=['time']) \n",
    "                    \n",
    "    #                 pred = model.predict(X_test)\n",
    "    #                 print (pred)\n",
    "\n",
    "                    prediction_proba = model.predict_proba(X_test)\n",
    "                    # prediction_proba è una matrice con due colonne: la prima colonna contiene le probabilità che il sample\n",
    "                    # appartenga alla classe \"N\", il secondo contiene la probabilità di appartenenza alla classe \"QP\".\n",
    "                    # quindi considerero la seconda colonna.\n",
    "                    \n",
    "#                     print (prediction_proba)\n",
    "                    prediction = []\n",
    "                    for el in prediction_proba:\n",
    "                        # nel caso in cui nel test set di una determinata fascia non siano presenti elementi QP\n",
    "                        # predict proba ritornerà una sola colonna con la probabilità di appartenenza alla classe negativa\n",
    "                        if len(el)>1:\n",
    "                            if el[1]>= threshold:\n",
    "                                prediction.append(\"QP\")\n",
    "                            else:\n",
    "                                prediction.append(\"N\")\n",
    "                        else:\n",
    "                            if 1-el >= threshold:\n",
    "                                prediction.append(\"QP\")\n",
    "                            else:\n",
    "                                prediction.append(\"N\")\n",
    "\n",
    "                    cm = confusion_matrix(y_test, prediction, labels=[\"N\", \"QP\"])\n",
    "\n",
    "                    str_= f'{classifier} FOR STATION {station_id}' + '\\n'\n",
    "                    str_ += f'Confusion matrix:' + '\\n'\n",
    "                    str_ += str(cm) + '\\n'\n",
    "\n",
    "                    tn, fp, fn, tp = cm.ravel()\n",
    "                    str_+= f'tp={tp}, fn={fn}, fp={fp}, tn={tn}' +'\\n'\n",
    "\n",
    "                    test_accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "        #             test_recall = (tp) / (tp + fn)\n",
    "        #             test_precision = (tp) / (tp + fp)\n",
    "                    test_recall = recall_score(y_test, prediction, pos_label='QP', zero_division=0)\n",
    "                    test_precision = precision_score(y_test, prediction, pos_label='QP', zero_division=0)\n",
    "                    test_f1_score = f1_score(y_test, prediction, pos_label='QP', zero_division=0)\n",
    "\n",
    "                    str_+= f'accuracy={test_accuracy}; recall={test_recall}; precision={test_precision}; f1_score= {test_f1_score}' +'\\n\\n'\n",
    "                    str_+= \"-\"*10 +'\\n\\n'\n",
    "\n",
    "                    tot_fp += fp\n",
    "                    tot_tp += tp\n",
    "                    tot_fn += fn\n",
    "                    tot_tn += tn\n",
    "\n",
    "                    file.write(str_)\n",
    "                \n",
    "\n",
    "                avg_accuracy = (tot_tn + tot_tp) / (tot_tn + tot_fp + tot_fn + tot_tp)\n",
    "                avg_recall = (tot_tp) / (tot_tp + tot_fn)\n",
    "                if (tot_tp + tot_fp) != 0.0:\n",
    "                    avg_precision = (tot_tp) / (tot_tp + tot_fp)\n",
    "                else:\n",
    "                    avg_precision = 0.0\n",
    "\n",
    "                if avg_recall!= 0.0 and avg_precision!= 0.0:\n",
    "                    avg_f1_score = 2*(1/((1/avg_recall)+(1/avg_precision)))\n",
    "                else:\n",
    "                    avg_f1_score = 0.0\n",
    "                result_matrix.append([avg_accuracy, avg_recall, avg_precision, avg_f1_score])\n",
    "                avg_str = f\"AVERAGE VALUES FOR {classifier} TEST:\\n\"\n",
    "                avg_str += \"Confusion matrix:\\n\"\n",
    "                avg_str += f\"[[{tot_tn} {tot_fp}]\\n[{tot_fn} {tot_tp}]]\\n\"\n",
    "                avg_str += f\"tot_tp={tot_tp}, tot_fn={tot_fn}, tot_fp={tot_fp}, tot_tn={tot_tn}\\n\"\n",
    "                avg_str += f\"accuracy={avg_accuracy}; recall={avg_recall}; precision={avg_precision}; f1_score={avg_f1_score}\\n\\n\"\n",
    "                \n",
    "                \n",
    "                file.write(avg_str)\n",
    "                file.close()\n",
    "\n",
    "        result_table = pd.DataFrame(result_matrix, columns=['avg_accuracy', 'avg_recall', 'avg_precision', 'avg_f1_score'], index=pd.Index(thresholds))\n",
    "        results_table[slot] = result_table\n",
    "        result_table.to_csv(f\"./test_results/tuned_classifiers_with_threshold_time_slots/Overall_results_{slot}_{scoring}_{interval}_{window_width}.csv\")\n",
    "\n",
    "# print(f\"[[{all_tn} {all_fp}]\\n[{all_fn} {all_tp}]]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-russell",
   "metadata": {},
   "source": [
    "#### Calcolo le matrici di confusione globali (sommando quelle diverse fasce orarie) per ciscuna soglia di porbabilità. In questo modo posso considerare le prestazioni medie considerando tutte le fasce orarie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "engaging-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOGLIA DI PROBABILITA':0.5\n",
      "[[302223 2674]\n",
      "[3425 7658]]\n",
      "all_tp=7658, all_fn=3425, all_fp=2674, all_tn=302223\n",
      "accuracy=0.9807; recall=0.69097; precision=0.74119; f1_score=0.7152\n",
      "\n",
      "\n",
      "SOGLIA DI PROBABILITA':0.6\n",
      "[[302885 2012]\n",
      "[4141 6942]]\n",
      "all_tp=6942, all_fn=4141, all_fp=2012, all_tn=302885\n",
      "accuracy=0.98053; recall=0.62636; precision=0.7753; f1_score=0.69292\n",
      "\n",
      "\n",
      "SOGLIA DI PROBABILITA':0.7\n",
      "[[303430 1467]\n",
      "[5107 5976]]\n",
      "all_tp=5976, all_fn=5107, all_fp=1467, all_tn=303430\n",
      "accuracy=0.97919; recall=0.5392; precision=0.8029; f1_score=0.64514\n",
      "\n",
      "\n",
      "SOGLIA DI PROBABILITA':0.8\n",
      "[[303849 1048]\n",
      "[6049 5034]]\n",
      "all_tp=5034, all_fn=6049, all_fp=1048, all_tn=303849\n",
      "accuracy=0.97754; recall=0.45421; precision=0.82769; f1_score=0.58654\n",
      "\n",
      "\n",
      "SOGLIA DI PROBABILITA':0.85\n",
      "[[304045 852]\n",
      "[6450 4633]]\n",
      "all_tp=4633, all_fn=6450, all_fp=852, all_tn=304045\n",
      "accuracy=0.97689; recall=0.41803; precision=0.84467; f1_score=0.55927\n",
      "\n",
      "\n",
      "SOGLIA DI PROBABILITA':0.9\n",
      "[[304109 788]\n",
      "[6927 4156]]\n",
      "all_tp=4156, all_fn=6927, all_fp=788, all_tn=304109\n",
      "accuracy=0.97558; recall=0.37499; precision=0.84061; f1_score=0.51863\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oa_recall</th>\n",
       "      <th>oa_precision</th>\n",
       "      <th>oa_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.69097</td>\n",
       "      <td>0.74119</td>\n",
       "      <td>0.71520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.62636</td>\n",
       "      <td>0.77530</td>\n",
       "      <td>0.69292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.53920</td>\n",
       "      <td>0.80290</td>\n",
       "      <td>0.64514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.45421</td>\n",
       "      <td>0.82769</td>\n",
       "      <td>0.58654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.41803</td>\n",
       "      <td>0.84467</td>\n",
       "      <td>0.55927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.37499</td>\n",
       "      <td>0.84061</td>\n",
       "      <td>0.51863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      oa_recall  oa_precision  oa_f1_score\n",
       "0.50    0.69097       0.74119      0.71520\n",
       "0.60    0.62636       0.77530      0.69292\n",
       "0.70    0.53920       0.80290      0.64514\n",
       "0.80    0.45421       0.82769      0.58654\n",
       "0.85    0.41803       0.84467      0.55927\n",
       "0.90    0.37499       0.84061      0.51863"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_conf_matrix = {}\n",
    "result_matrix = []\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.85, 0.9]\n",
    "curret_scoring = \"precision\"\n",
    "current_interval = 30\n",
    "current_window_width = 5\n",
    "current_time_slots = [\n",
    "    \"0-6\", \n",
    "    \"6-10\", \n",
    "    \"10-14\", \n",
    "    \"14-17\", \n",
    "    \"17-20\", \n",
    "    \"20-24\"\n",
    "]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"SOGLIA DI PROBABILITA\\':{threshold}\")\n",
    "    all_fp=0\n",
    "    all_tp=0\n",
    "    all_fn=0\n",
    "    all_tn=0\n",
    "    \n",
    "    for slot in current_time_slots:\n",
    "        \n",
    "        input_file_name = f\"results_{slot}_DecisionTree_precision_30_5_({int(threshold*100)}%).txt\"\n",
    "        input_file_path = f\"./test_results/tuned_classifiers_with_threshold_time_slots/{input_file_name}\" \n",
    "        \n",
    "        with open(input_file_path, \"r\") as file:\n",
    "            lines = file.read().splitlines()\n",
    "            last_line = lines[-3]\n",
    "#             print (last_line)\n",
    "            results = last_line.split(', ')\n",
    "            result_values = []\n",
    "            for result in results:\n",
    "#                 print (result)\n",
    "                value = int(result.split('=')[1])\n",
    "                result_values.append(value)\n",
    "        all_tp+=result_values[0]   \n",
    "        all_fn+=result_values[1]\n",
    "        all_fp+=result_values[2]\n",
    "        all_tn+=result_values[3]\n",
    "        \n",
    "    avg_accuracy = round((all_tn + all_tp) / (all_tn + all_fp + all_fn + all_tp), 5)\n",
    "    avg_recall = round((all_tp) / (all_tp + all_fn), 5)\n",
    "    if (all_tp + all_fp) != 0.0:\n",
    "        avg_precision = round((all_tp) / (all_tp + all_fp), 5)\n",
    "    else:\n",
    "        avg_precision = 0.0\n",
    "\n",
    "    if avg_recall!= 0.0 and avg_precision!= 0.0:\n",
    "        avg_f1_score = round(2*(1/((1/avg_recall)+(1/avg_precision))), 5)\n",
    "    else:\n",
    "        avg_f1_score = 0.0\n",
    "\n",
    "#     result_matrix.append([avg_accuracy, avg_recall, avg_precision, avg_f1_score])\n",
    "    result_matrix.append([avg_recall, avg_precision, avg_f1_score])\n",
    "    final_str = f\"[[{all_tn} {all_fp}]\\n[{all_fn} {all_tp}]]\\n\"\n",
    "    final_str += f\"all_tp={all_tp}, all_fn={all_fn}, all_fp={all_fp}, all_tn={all_tn}\\n\"\n",
    "    final_str += f\"accuracy={round(avg_accuracy, 5)}; recall={round(avg_recall, 5)}; precision={round(avg_precision, 5)}; f1_score={round(avg_f1_score, 5)}\\n\\n\"\n",
    "    print (final_str)\n",
    "    total_conf_matrix[threshold] = [all_tp, all_fn, all_fp, all_tn]\n",
    "\n",
    "# result_table = pd.DataFrame(result_matrix, columns=['avg_accuracy', 'avg_recall', 'avg_precision', 'avg_f1_score'], index=pd.Index(thresholds))\n",
    "result_table = pd.DataFrame(result_matrix, columns=['oa_recall', 'oa_precision', 'oa_f1_score'], index=pd.Index(thresholds))\n",
    "# result_table.to_csv(f\"./test_results/tuned_classifiers_with_threshold_time_slots/Overall_results_AllSlots_{curret_scoring}_{current_interval}_{current_window_width}.csv\")\n",
    "# print(result_table.to_latex(bold_rows=True))\n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forced-carnival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  avg\\_recall &  avg\\_precision &  avg\\_f1\\_score \\\\\n",
      "\\midrule\n",
      "\\textbf{0.50} &    0.814674 &       0.842135 &      0.828177 \\\\\n",
      "\\textbf{0.60} &    0.791304 &       0.852459 &      0.820744 \\\\\n",
      "\\textbf{0.70} &    0.789674 &       0.852199 &      0.819746 \\\\\n",
      "\\textbf{0.80} &    0.760326 &       0.857230 &      0.805876 \\\\\n",
      "\\textbf{0.85} &    0.715217 &       0.869795 &      0.784969 \\\\\n",
      "\\textbf{0.90} &    0.536413 &       0.854545 &      0.659098 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.814674</td>\n",
       "      <td>0.842135</td>\n",
       "      <td>0.828177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.820744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.789674</td>\n",
       "      <td>0.852199</td>\n",
       "      <td>0.819746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.760326</td>\n",
       "      <td>0.857230</td>\n",
       "      <td>0.805876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.715217</td>\n",
       "      <td>0.869795</td>\n",
       "      <td>0.784969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.536413</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.659098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_recall  avg_precision  avg_f1_score\n",
       "0.50    0.814674       0.842135      0.828177\n",
       "0.60    0.791304       0.852459      0.820744\n",
       "0.70    0.789674       0.852199      0.819746\n",
       "0.80    0.760326       0.857230      0.805876\n",
       "0.85    0.715217       0.869795      0.784969\n",
       "0.90    0.536413       0.854545      0.659098"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Codice per ottenere il latex delle diverse tabelle\n",
    "time_slot = \"20-24\"\n",
    "res_df = pd.read_csv(f\"./test_results/tuned_classifiers_with_threshold_time_slots/Overall_results_{time_slot}_precision_30_5.csv\", index_col=0)\n",
    "res_df = res_df.drop(columns=['avg_accuracy']).drop([0.95])\n",
    "print(res_df.to_latex(bold_rows=True))\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jewish-despite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  avg\\_recall &  avg\\_precision &  avg\\_f1\\_score \\\\\n",
      "\\midrule\n",
      "\\textbf{0-6(90\\%)  } &      0.7729 &         0.9376 &        0.8473 \\\\\n",
      "\\textbf{6-10(60\\%) } &      0.3600 &         0.5703 &        0.4414 \\\\\n",
      "\\textbf{10-14(60\\%)} &      0.5398 &         0.6572 &        0.5927 \\\\\n",
      "\\textbf{14-17(60\\%)} &      0.3165 &         0.5498 &        0.4018 \\\\\n",
      "\\textbf{17-20(70\\%)} &      0.2576 &         0.5846 &        0.3576 \\\\\n",
      "\\textbf{20-24(85\\%)} &      0.7152 &         0.8698 &        0.7850 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-6(90%)</th>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.8473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6-10(60%)</th>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.5703</td>\n",
       "      <td>0.4414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-14(60%)</th>\n",
       "      <td>0.5398</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.5927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14-17(60%)</th>\n",
       "      <td>0.3165</td>\n",
       "      <td>0.5498</td>\n",
       "      <td>0.4018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17-20(70%)</th>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20-24(85%)</th>\n",
       "      <td>0.7152</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.7850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_recall  avg_precision  avg_f1_score\n",
       "0-6(90%)        0.7729         0.9376        0.8473\n",
       "6-10(60%)       0.3600         0.5703        0.4414\n",
       "10-14(60%)      0.5398         0.6572        0.5927\n",
       "14-17(60%)      0.3165         0.5498        0.4018\n",
       "17-20(70%)      0.2576         0.5846        0.3576\n",
       "20-24(85%)      0.7152         0.8698        0.7850"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RISULTATI MIGLIORI\n",
    "\n",
    "best_results ={\n",
    "    \"0-6\" : [90],     \n",
    "    \"6-10\" : [60],    \n",
    "    \"10-14\" : [60],     \n",
    "    \"14-17\" : [60],     \n",
    "    \"17-20\" : [70],     \n",
    "    \"20-24\" : [85]   \n",
    "}\n",
    "\n",
    "rows = []\n",
    "result_matrix = []\n",
    "columns = [\"avg_recall\", \"avg_precision\", \"avg_f1_score\"]\n",
    "\n",
    "for slot in best_results.keys():\n",
    "    for prob in best_results[slot]:\n",
    "\n",
    "        input_file_name = f\"results_{slot}_DecisionTree_precision_30_5_({prob}%).txt\"\n",
    "        \n",
    "        input_file_path = f\"./test_results/tuned_classifiers_with_threshold_time_slots/{input_file_name}\"\n",
    "\n",
    "        row = f\"{slot}({prob}%)\"\n",
    "        rows.append(row)\n",
    "        with open(input_file_path, \"r\") as file:\n",
    "            lines = file.read().splitlines()\n",
    "            last_line = lines[-2]\n",
    "#             print (last_line)\n",
    "            results = last_line.split(';')\n",
    "            result_values = []\n",
    "            for result in results:\n",
    "                \n",
    "                value = round(float(result.split('=')[1]), 4)\n",
    "                result_values.append(value)\n",
    "            result_matrix.append(result_values[1:])\n",
    "\n",
    "results_table = pd.DataFrame(result_matrix, columns=columns, index=pd.Index(rows))\n",
    "print(results_table.to_latex(bold_rows=True))\n",
    "results_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(80,40))\n",
    "# tree.plot_tree(model, fontsize=10, feature_names=X.columns, class_names=['N', 'QP'], label='all', filled=True, rounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-nebraska",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aggregate-journal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- TIME SLOT 0-6 ----\n",
      "Number of total training records: 19072\n",
      "Number of training records QP: 41\n",
      "Number of test records: 2216\n",
      "Number of test records QP: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DISTRIBUZIONI DEI DATASETS\n",
    "\n",
    "for slot in time_slots:\n",
    "    print(f\"---- TIME SLOT {slot} ----\")\n",
    "    for reference_station in San_Fancisco_stations:\n",
    "        train_df = pd.read_csv(f\"./datasets/{interval}_{window_width}/Train_test_with_time/station62_train.csv\")\n",
    "        print (f\"Number of total training records: {len(train_df)}\")\n",
    "        total_num_QP =  train_df[train_df['status']=='QP']\n",
    "        print (f\"Number of training records QP: {len(total_num_QP)}\")\n",
    "        \n",
    "        time_slot_train_df = train_df.set_index(\"time\", drop=True)\n",
    "        time_slot_train_df.index=pd.to_datetime(time_slot_train_df.index)\n",
    "        start_time= slot.split('-')[0]\n",
    "        end_time = slot.split('-')[1]\n",
    "        if end_time != '24':       \n",
    "            time_slot_train_df = time_slot_train_df.between_time(f'{start_time}:00', f'{end_time}:00')\n",
    "        else:\n",
    "            time_slot_train_df = time_slot_train_df.between_time(f'{start_time}:00', '23:59')\n",
    "\n",
    "        y = time_slot_train_df['status']\n",
    "        num_QP =  time_slot_train_df[time_slot_train_df['status']=='QP']\n",
    "        X = time_slot_train_df.drop(columns=['status'])\n",
    "        X = X.reset_index().drop(columns=['time'])\n",
    "#         print (f\"Number of training records: {len(X)}\")\n",
    "#         print (f\"Number of training records QP: {len(num_QP)}\")\n",
    "        \n",
    "        \n",
    "        test_df = pd.read_csv(f'./datasets/{interval}_{window_width}/Train_test_with_time/station62_test.csv')\n",
    "#         print (f\"Number of total test records: {len(test_df)}\")\n",
    "#         total_num_QP =  test_df[test_df['status']=='QP']\n",
    "#         print (f\"Number of test records QP: {len(total_num_QP)}\") \n",
    "        \n",
    "        time_slot_test_df = test_df.set_index(\"time\", drop=True)\n",
    "        time_slot_test_df.index=pd.to_datetime(time_slot_test_df.index)\n",
    "        start_time= slot.split('-')[0]\n",
    "        end_time = slot.split('-')[1]\n",
    "        if end_time != '24':       \n",
    "            time_slot_test_df = time_slot_test_df.between_time(f'{start_time}:00', f'{end_time}:00')\n",
    "        else:\n",
    "            time_slot_test_df = time_slot_test_df.between_time(f'{start_time}:00', '23:59')\n",
    "\n",
    "        y_test = time_slot_test_df['status']\n",
    "        num_QP =  time_slot_test_df[time_slot_test_df['status']=='QP']\n",
    "        X_test = time_slot_test_df.drop(columns=['status']) \n",
    "        X_test = X_test.reset_index().drop(columns=['time']) \n",
    "        print (f\"Number of test records: {len(X_test)}\")\n",
    "        print (f\"Number of test records QP: {len(num_QP)}\\n\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-venezuela",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-competition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
