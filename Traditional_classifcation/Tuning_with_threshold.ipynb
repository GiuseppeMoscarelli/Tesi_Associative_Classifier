{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "banned-essay",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from math import sin, cos, sqrt, atan2, radians \n",
    "from sklearn import tree, svm, linear_model, ensemble, neighbors, naive_bayes \n",
    "import dateutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mounted-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_path = Path('../filtered_status.csv')\n",
    "stations_path = Path('../station.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coated-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df = pd.read_csv(status_path, parse_dates=['time'])\n",
    "stations_df = pd.read_csv(stations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brave-schedule",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>bikes_available</th>\n",
       "      <th>docks_available</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:06:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:07:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:08:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:09:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2013-08-29 12:10:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977905</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:55:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977906</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:56:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977907</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:57:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977908</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:58:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71977909</th>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-08-31 23:59:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71977910 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          station_id  bikes_available  docks_available                time\n",
       "0                  2                2               25 2013-08-29 12:06:01\n",
       "1                  2                2               25 2013-08-29 12:07:01\n",
       "2                  2                2               25 2013-08-29 12:08:01\n",
       "3                  2                2               25 2013-08-29 12:09:01\n",
       "4                  2                2               25 2013-08-29 12:10:01\n",
       "...              ...              ...              ...                 ...\n",
       "71977905          84                8                7 2015-08-31 23:55:02\n",
       "71977906          84                8                7 2015-08-31 23:56:01\n",
       "71977907          84                8                7 2015-08-31 23:57:02\n",
       "71977908          84                8                7 2015-08-31 23:58:02\n",
       "71977909          84                8                7 2015-08-31 23:59:02\n",
       "\n",
       "[71977910 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "diagnostic-illness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dock_count</th>\n",
       "      <th>city</th>\n",
       "      <th>installation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>San Jose Diridon Caltrain Station</td>\n",
       "      <td>37.329732</td>\n",
       "      <td>-121.901782</td>\n",
       "      <td>27</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/6/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>San Jose Civic Center</td>\n",
       "      <td>37.330698</td>\n",
       "      <td>-121.888979</td>\n",
       "      <td>15</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/5/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Santa Clara at Almaden</td>\n",
       "      <td>37.333988</td>\n",
       "      <td>-121.894902</td>\n",
       "      <td>11</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/6/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Adobe on Almaden</td>\n",
       "      <td>37.331415</td>\n",
       "      <td>-121.893200</td>\n",
       "      <td>19</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/5/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>San Pedro Square</td>\n",
       "      <td>37.336721</td>\n",
       "      <td>-121.894074</td>\n",
       "      <td>15</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>8/7/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>77</td>\n",
       "      <td>Market at Sansome</td>\n",
       "      <td>37.789625</td>\n",
       "      <td>-122.400811</td>\n",
       "      <td>27</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>8/25/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>80</td>\n",
       "      <td>Santa Clara County Civic Center</td>\n",
       "      <td>37.352601</td>\n",
       "      <td>-121.905733</td>\n",
       "      <td>15</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>12/31/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>82</td>\n",
       "      <td>Broadway St at Battery St</td>\n",
       "      <td>37.798541</td>\n",
       "      <td>-122.400862</td>\n",
       "      <td>15</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1/22/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>83</td>\n",
       "      <td>Mezes Park</td>\n",
       "      <td>37.491269</td>\n",
       "      <td>-122.236234</td>\n",
       "      <td>15</td>\n",
       "      <td>Redwood City</td>\n",
       "      <td>2/20/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>84</td>\n",
       "      <td>Ryland Park</td>\n",
       "      <td>37.342725</td>\n",
       "      <td>-121.895617</td>\n",
       "      <td>15</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>4/9/2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                               name        lat        long  dock_count  \\\n",
       "0    2  San Jose Diridon Caltrain Station  37.329732 -121.901782          27   \n",
       "1    3              San Jose Civic Center  37.330698 -121.888979          15   \n",
       "2    4             Santa Clara at Almaden  37.333988 -121.894902          11   \n",
       "3    5                   Adobe on Almaden  37.331415 -121.893200          19   \n",
       "4    6                   San Pedro Square  37.336721 -121.894074          15   \n",
       "..  ..                                ...        ...         ...         ...   \n",
       "65  77                  Market at Sansome  37.789625 -122.400811          27   \n",
       "66  80    Santa Clara County Civic Center  37.352601 -121.905733          15   \n",
       "67  82          Broadway St at Battery St  37.798541 -122.400862          15   \n",
       "68  83                         Mezes Park  37.491269 -122.236234          15   \n",
       "69  84                        Ryland Park  37.342725 -121.895617          15   \n",
       "\n",
       "             city installation_date  \n",
       "0        San Jose          8/6/2013  \n",
       "1        San Jose          8/5/2013  \n",
       "2        San Jose          8/6/2013  \n",
       "3        San Jose          8/5/2013  \n",
       "4        San Jose          8/7/2013  \n",
       "..            ...               ...  \n",
       "65  San Francisco         8/25/2013  \n",
       "66       San Jose        12/31/2013  \n",
       "67  San Francisco         1/22/2014  \n",
       "68   Redwood City         2/20/2014  \n",
       "69       San Jose          4/9/2014  \n",
       "\n",
       "[70 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-planning",
   "metadata": {},
   "source": [
    "## Ottengo gli id delle stazioni per ogni città diversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stainless-invalid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['San Jose', 'Redwood City', 'Mountain View', 'Palo Alto',\n",
       "       'San Francisco'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = stations_df['city'].unique()\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "julian-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'San Jose': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 16, 80, 84]),\n",
       " 'Redwood City': array([21, 22, 23, 24, 25, 26, 83]),\n",
       " 'Mountain View': array([27, 28, 29, 30, 31, 32, 33]),\n",
       " 'Palo Alto': array([34, 35, 36, 37, 38]),\n",
       " 'San Francisco': array([41, 42, 45, 46, 47, 48, 49, 50, 51, 39, 54, 55, 56, 57, 58, 59, 60,\n",
       "        61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
       "        82])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_stations = {}\n",
    "\n",
    "for city in cities:\n",
    "    city_stations[city] = stations_df[stations_df['city'] == city]['id'].unique()\n",
    "\n",
    "city_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-closer",
   "metadata": {},
   "source": [
    "## Prendo in cosiderazione solo gli id delle stazioni appartenenti alla città di San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hundred-fireplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 42, 45, 46, 47, 48, 49, 50, 51, 39, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
       "       82])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "San_Fancisco_stations = city_stations[\"San Francisco\"]\n",
    "San_Fancisco_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cardiovascular-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval=30\n",
    "window_width = 5\n",
    "drop_bikes_inf = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-assessment",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crazy-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'DecisionTree': tree.DecisionTreeClassifier(random_state=42),   \n",
    "#     'SVC': svm.SVC(),\n",
    "#     'LogisticRegression': linear_model.LogisticRegression(random_state=42, solver='liblinear', max_iter=1000),\n",
    "#     'NaiveBayes': naive_bayes.GaussianNB(),\n",
    "#     'RandomForest': ensemble.RandomForestClassifier(random_state=42, max_features='sqrt'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-walker",
   "metadata": {},
   "source": [
    "Effettuo il finetuning dei modelli tramite la grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "variable-kennedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 41 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 41 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 41 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 41 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 42 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 42 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 42 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 42 using the scoring f1_score: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 45 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 45 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 45 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 45 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 46 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 46 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 46 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 46 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 47 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 47 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 47 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 47 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 48 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 48 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 48 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 48 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 49 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 49 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 49 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 49 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 50 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 50 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 50 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 50 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 51 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 51 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 51 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 51 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 39 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 39 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 39 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 39 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 54 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 54 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 54 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 54 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 55 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 55 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 55 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 55 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 56 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 56 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 56 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 56 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 57 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 57 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 57 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 57 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 58 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 58 using the scoring recall: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 58 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 4}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 58 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 59 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 59 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 59 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 59 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 60 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 60 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 60 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 60 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 61 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 61 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 61 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 61 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 62 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 62 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 62 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 5}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 62 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 63 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 63 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 63 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 63 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 64 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 64 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 64 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 64 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 65 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 65 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 65 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 65 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 66 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 66 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 66 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 66 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 67 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 67 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 67 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 67 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 68 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 68 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 68 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 68 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 69 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 69 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 69 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 69 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 70 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 70 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 70 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 70 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 71 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 71 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 71 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 71 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 72 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 72 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 72 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 72 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 73 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 73 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 73 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 73 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 74 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 74 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 74 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 74 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 75 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 75 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 75 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 75 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 76 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 76 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 76 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 76 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 77 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 77 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 77 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 77 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 82 using the scoring accuracy: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 82 using the scoring recall: \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 82 using the scoring precision: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "----------\n",
      "Best parameters for classifier DecisionTree for the station 82 using the scoring f1_score: \n",
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_parameters = {\n",
    "    'max_depth': list(range(2, 7)),\n",
    "    'min_samples_split': list(range(2, 7)),\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "SVC_parameters = {\n",
    "    'C': [0.1, 1, 100],\n",
    "    'gamma': [0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "logistic_regression_parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1, 0.1, 0.01, 0.001],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "random_forest_parameters = {\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth': list(range(0, 5)), \n",
    "    'min_samples_split': list(range(0, 5)), \n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "naive_bayes_parameters = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "classifiers_parameters = {\n",
    "  'DecisionTree': decision_tree_parameters,\n",
    "  'SVC': SVC_parameters,\n",
    "  'LogisticRegression': logistic_regression_parameters,\n",
    "  'RandomForest': random_forest_parameters,\n",
    "  'NaiveBayes': naive_bayes_parameters\n",
    "}\n",
    "\n",
    "tuned_classifiers = {\n",
    "    'DecisionTree': [],\n",
    "    'SVC': [],\n",
    "    'LogisticRegression': [],\n",
    "    'RandomForest': [],\n",
    "    'KNN': []\n",
    "}\n",
    "\n",
    "for reference_station in San_Fancisco_stations:\n",
    "    train_df = pd.read_csv(f\"./datasets/{interval}_{window_width}/station{reference_station}_train.csv\")\n",
    "    \n",
    "    # se il flag è a true, rimuovo tutte le informazioni relative alle bici disponibili\n",
    "    if drop_bikes_inf:\n",
    "        train_df = train_df[train_df.columns.drop(list(train_df.filter(regex='bikes')))]\n",
    "        \n",
    "    y = train_df['status']\n",
    "    X = train_df.drop(columns=['status'])\n",
    "\n",
    "    for scoring in ['accuracy', 'recall', 'precision', 'f1_score']:\n",
    "        for classifier in classifiers.keys():\n",
    "            print(f\"Classifier: {classifier}\" )   \n",
    "        \n",
    "            clf = classifiers[classifier]\n",
    "            parametrers = classifiers_parameters[classifier]\n",
    "            \n",
    "            #I segunti controlli sono necessari in quanto richiamo, precisione e \n",
    "            # f1score hanno necessità di conoscere quale sia la classe positiva (QP)\n",
    "            if scoring == \"recall\":\n",
    "                scorer = make_scorer(recall_score, pos_label=\"QP\")\n",
    "            elif scoring == \"precision\":\n",
    "                scorer = make_scorer(precision_score, pos_label=\"QP\")\n",
    "            elif scoring == \"f1_score\":\n",
    "                scorer = make_scorer(f1_score, pos_label=\"QP\")\n",
    "            else:\n",
    "                scorer = scoring\n",
    "            \n",
    "            #Nel caso di logist regression utilizzo la randomizedSearchCV, in quanto più veloce rispetto alla gridSearchCV\n",
    "            if classifier == 'LogisticRegression':\n",
    "                search_result = RandomizedSearchCV(clf, parametrers, scoring=scorer, random_state=42, n_iter=5, n_jobs=-1)\n",
    "            else:\n",
    "                search_result = GridSearchCV(clf, parametrers, scoring=scorer, cv=3, n_jobs=-1)\n",
    "                \n",
    "            fit_result = search_result.fit(X, y)\n",
    "            params = fit_result.best_params_\n",
    "\n",
    "            print(\"-\"*10)\n",
    "            print(f\"Best parameters for classifier {classifier} for the station {reference_station} using the scoring {scoring}: \")\n",
    "            print(params)\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "            tuned_clf = search_result.best_estimator_\n",
    "            \n",
    "            #salvo il modello dopo il fine tuning\n",
    "            if drop_bikes_inf:\n",
    "                if (Path.cwd() / f'tuned_models_wo_bikes_inf/{scoring}/{classifier}/{interval}_{window_width}').exists() == False:\n",
    "                    os.makedirs(f\"./tuned_models_wo_bikes_inf/{scoring}/{classifier}/{interval}_{window_width}\")\n",
    "                dump(tuned_clf, f'./tuned_models_wo_bikes_inf/{scoring}/{classifier}/{interval}_{window_width}/station{reference_station}_tuned_model.joblib')\n",
    "            else:\n",
    "                if (Path.cwd() / f'tuned_models/{scoring}/{classifier}/{interval}_{window_width}').exists() == False:\n",
    "                    os.makedirs(f\"./tuned_models/{scoring}/{classifier}/{interval}_{window_width}\")\n",
    "                dump(tuned_clf, f'./tuned_models/{scoring}/{classifier}/{interval}_{window_width}/station{reference_station}_tuned_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-designation",
   "metadata": {},
   "source": [
    "## Testing dei fine tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_table = {}\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95]\n",
    "\n",
    "for scoring in [\"precision\"]:\n",
    "    result_matrix = []\n",
    "    for classifier in classifiers.keys():\n",
    "        for threshold in thresholds:\n",
    "            \n",
    "            if drop_bikes_inf:\n",
    "                file = open(f'test_results/tuned_classifiers_with_threshold/without_bikes_inf/{classifier}_{scoring}_{interval}_{window_width}_({int(threshold*100)}%)_results.txt', \"w\")\n",
    "            else:\n",
    "                file = open(f'test_results/tuned_classifiers_with_threshold/{classifier}_{scoring}_{interval}_{window_width}_({int(threshold*100)}%)_results.txt', \"w\")\n",
    "            file.write(f'TESING RESULTS FOR {classifier} CLASSIFIER WITH THRESHOLD {int(threshold*100)}%:\\n\\n')\n",
    "            tot_fp = 0\n",
    "            tot_tp = 0\n",
    "            tot_fn = 0\n",
    "            tot_tn = 0\n",
    "\n",
    "            for station_id in San_Fancisco_stations:\n",
    "                \n",
    "                if drop_bikes_inf:\n",
    "                    model = load(f'./tuned_models_wo_bikes_inf/{scoring}/{classifier}/{interval}_{window_width}/station{station_id}_tuned_model.joblib')\n",
    "                else:\n",
    "                    model = load(f'./tuned_models/{scoring}/{classifier}/{interval}_{window_width}/station{station_id}_tuned_model.joblib')\n",
    "                \n",
    "                test_df = pd.read_csv(f'./datasets/{interval}_{window_width}/station{station_id}_test.csv')\n",
    "                \n",
    "                #se il flag è true, rimuovo le info sulle biciclette\n",
    "                if drop_bikes_inf:\n",
    "                    test_df = test_df[test_df.columns.drop(list(test_df.filter(regex='bikes')))]\n",
    "                \n",
    "                y_test = test_df['status']\n",
    "                X_test = test_df.drop(columns=['status'])    \n",
    "\n",
    "#                 pred = model.predict(X_test)\n",
    "#                 print (pred)\n",
    "\n",
    "                prediction_proba = model.predict_proba(X_test)\n",
    "                # prediction_proba è una matrice con due colonne: la prima colonna contiene le probabilità che il sample\n",
    "                # appartenga alla classe \"N\", il secondo contiene la probabilità di appartenenza alla classe \"QP\".\n",
    "                # quindi considerero la seconda colonna.\n",
    "\n",
    "                prediction = []\n",
    "                for el in prediction_proba:\n",
    "                    if el[1] >= threshold:\n",
    "                        prediction.append(\"QP\")\n",
    "                    else:\n",
    "                        prediction.append(\"N\")\n",
    "\n",
    "                cm = confusion_matrix(y_test, prediction)\n",
    "\n",
    "                str_= f'{classifier} FOR STATION {station_id}' + '\\n'\n",
    "                str_ += f'Confusion matrix:' + '\\n'\n",
    "                str_ += str(cm) + '\\n'\n",
    "\n",
    "                tn, fp, fn, tp = cm.ravel()\n",
    "                str_+= f'tp={tp}, fn={fn}, fp={fp}, tn={tn}' +'\\n'\n",
    "\n",
    "                test_accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "    #             test_recall = (tp) / (tp + fn)\n",
    "    #             test_precision = (tp) / (tp + fp)\n",
    "                test_recall = recall_score(y_test, prediction, pos_label='QP')\n",
    "                test_precision = precision_score(y_test, prediction, pos_label='QP', zero_division=0)\n",
    "                test_f1_score = f1_score(y_test, prediction, pos_label='QP')\n",
    "\n",
    "                str_+= f'accuracy={test_accuracy}; recall={test_recall}; precision={test_precision}; f1_score= {test_f1_score}' +'\\n\\n'\n",
    "                str_+= \"-\"*10 +'\\n\\n'\n",
    "\n",
    "                tot_fp += fp\n",
    "                tot_tp += tp\n",
    "                tot_fn += fn\n",
    "                tot_tn += tn\n",
    "\n",
    "                file.write(str_)\n",
    "\n",
    "            avg_accuracy = (tot_tn + tot_tp) / (tot_tn + tot_fp + tot_fn + tot_tp)\n",
    "            avg_recall = (tot_tp) / (tot_tp + tot_fn)\n",
    "            avg_precision = (tot_tp) / (tot_tp + tot_fp)\n",
    "            avg_f1_score = 2*(1/((1/avg_recall)+(1/avg_precision)))\n",
    "\n",
    "            result_matrix.append([avg_accuracy, avg_recall, avg_precision, avg_f1_score])\n",
    "            avg_str = f\"AVERAGE VALUES FOR {classifier}: accuracy={avg_accuracy}; recall={avg_recall}; precision={avg_precision}; f1_score={avg_f1_score}\"\n",
    "\n",
    "            file.write(avg_str)\n",
    "            file.close()\n",
    "\n",
    "    result_table = pd.DataFrame(result_matrix, columns=['avg_accuracy', 'avg_recall', 'avg_precision', 'avg_f1_score'], index=pd.Index(thresholds))\n",
    "    results_table[scoring] = result_table\n",
    "    if drop_bikes_inf:\n",
    "        result_table.to_csv(f\"./test_results/tuned_classifiers_with_threshold/without_bikes_inf/Overall_results_{scoring}_{interval}_{window_width}.csv\")\n",
    "    else:\n",
    "        result_table.to_csv(f\"./test_results/tuned_classifiers_with_threshold/Overall_results_{scoring}_{interval}_{window_width}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fifty-concern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.73314</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>0.75184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.65806</td>\n",
       "      <td>0.79916</td>\n",
       "      <td>0.72178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.60791</td>\n",
       "      <td>0.81685</td>\n",
       "      <td>0.69706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.47587</td>\n",
       "      <td>0.84182</td>\n",
       "      <td>0.60803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.36756</td>\n",
       "      <td>0.84898</td>\n",
       "      <td>0.51301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.04768</td>\n",
       "      <td>0.90943</td>\n",
       "      <td>0.09060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_recall  avg_precision  avg_f1_score\n",
       "0.50     0.73314        0.77152       0.75184\n",
       "0.60     0.65806        0.79916       0.72178\n",
       "0.70     0.60791        0.81685       0.69706\n",
       "0.80     0.47587        0.84182       0.60803\n",
       "0.85     0.36756        0.84898       0.51301\n",
       "0.90     0.04768        0.90943       0.09060"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "result_matrix = []\n",
    "columns = [\"avg_recall\", \"avg_precision\", \"avg_f1_score\"]\n",
    "\n",
    "curr_drop_bikes_inf = True\n",
    "\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.85, 0.9]\n",
    "current_scoring = \"precision\"\n",
    "current_interval = 30\n",
    "current_window_width = 5\n",
    "\n",
    "\n",
    "for threshold in thresholds:\n",
    "    \n",
    "    input_file_name = f\"DecisionTree_{current_scoring}_{current_interval}_{current_window_width}_({int(threshold*100)}%)_results.txt\"\n",
    "\n",
    "    if curr_drop_bikes_inf:   \n",
    "        input_file_path = f\"./test_results/tuned_classifiers_with_threshold/without_bikes_inf/{input_file_name}\"\n",
    "    else:\n",
    "        input_file_path = f\"./test_results/tuned_classifiers_with_threshold/{input_file_name}\"\n",
    "        \n",
    "    with open(input_file_path, \"r\") as file:\n",
    "        lines = file.read().splitlines()\n",
    "        last_line = lines[-1]\n",
    "#                         print (last_line)\n",
    "        results = last_line.split(';')\n",
    "        result_values = []\n",
    "        for result in results:\n",
    "            value = round(float(result.split('=')[1]), 5)\n",
    "            result_values.append(value)\n",
    "        result_matrix.append(result_values[1:])\n",
    "\n",
    "results_table = pd.DataFrame(result_matrix, columns=columns, index=pd.Index(thresholds))\n",
    "# print(results_table.to_latex(float_format=\"%.4f\", bold_rows=True))\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technical-trick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  avg\\_recall &  avg\\_precision &  avg\\_f1\\_score \\\\\n",
      "\\midrule\n",
      "\\textbf{0.50} &     0.72433 &        0.77377 &       0.74824 \\\\\n",
      "\\textbf{0.60} &     0.65124 &        0.80410 &       0.71964 \\\\\n",
      "\\textbf{0.70} &     0.60544 &        0.82294 &       0.69763 \\\\\n",
      "\\textbf{0.80} &     0.48981 &        0.84650 &       0.62055 \\\\\n",
      "\\textbf{0.85} &     0.38061 &        0.85625 &       0.52698 \\\\\n",
      "\\textbf{0.90} &     0.05490 &        0.92040 &       0.10361 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Codice per ottenere il latex delle diverse tabelle\n",
    "print(results_table.to_latex(bold_rows=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "immune-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.733136</td>\n",
       "      <td>0.771521</td>\n",
       "      <td>0.751839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.658061</td>\n",
       "      <td>0.799159</td>\n",
       "      <td>0.721779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.607913</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.697062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.475865</td>\n",
       "      <td>0.841820</td>\n",
       "      <td>0.608025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.367557</td>\n",
       "      <td>0.848983</td>\n",
       "      <td>0.513012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.047676</td>\n",
       "      <td>0.909434</td>\n",
       "      <td>0.090602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_recall  avg_precision  avg_f1_score\n",
       "0.50    0.733136       0.771521      0.751839\n",
       "0.60    0.658061       0.799159      0.721779\n",
       "0.70    0.607913       0.816853      0.697062\n",
       "0.80    0.475865       0.841820      0.608025\n",
       "0.85    0.367557       0.848983      0.513012\n",
       "0.90    0.047676       0.909434      0.090602"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_drop_bikes_inf = False\n",
    "\n",
    "# stampo i risultati ottenuti leggendoli nel file csv salvato in caso di mancanza di bici\n",
    "\n",
    "if curr_drop_bikes_inf:\n",
    "    res = pd.read_csv(f\"./test_results/tuned_classifiers_with_threshold/without_bikes_inf/Overall_results_precision_30_5.csv\", index_col=0)\n",
    "\n",
    "else:\n",
    "    res = pd.read_csv(f\"./test_results/tuned_classifiers_with_threshold/without_bikes_inf/Overall_results_precision_30_5.csv\", index_col=0)\n",
    "res = res.drop(columns = ['avg_accuracy'])\n",
    "res = res.drop([0.95])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mathematical-snake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION FOR DECISION TREE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.982899</td>\n",
       "      <td>0.733136</td>\n",
       "      <td>0.771521</td>\n",
       "      <td>0.751839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.982074</td>\n",
       "      <td>0.658061</td>\n",
       "      <td>0.799159</td>\n",
       "      <td>0.721779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.981330</td>\n",
       "      <td>0.607913</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.697062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.978321</td>\n",
       "      <td>0.475865</td>\n",
       "      <td>0.841820</td>\n",
       "      <td>0.608025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.975343</td>\n",
       "      <td>0.367557</td>\n",
       "      <td>0.848983</td>\n",
       "      <td>0.513012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.966183</td>\n",
       "      <td>0.047676</td>\n",
       "      <td>0.909434</td>\n",
       "      <td>0.090602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>0.966032</td>\n",
       "      <td>0.042136</td>\n",
       "      <td>0.924078</td>\n",
       "      <td>0.080598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_accuracy  avg_recall  avg_precision  avg_f1_score\n",
       "0.50      0.982899    0.733136       0.771521      0.751839\n",
       "0.60      0.982074    0.658061       0.799159      0.721779\n",
       "0.70      0.981330    0.607913       0.816853      0.697062\n",
       "0.80      0.978321    0.475865       0.841820      0.608025\n",
       "0.85      0.975343    0.367557       0.848983      0.513012\n",
       "0.90      0.966183    0.047676       0.909434      0.090602\n",
       "0.95      0.966032    0.042136       0.924078      0.080598"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"PRECISION FOR DECISION TREE\")\n",
    "results_table[\"precision\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "flying-simple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION FOR DECISION TREE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.982777</td>\n",
       "      <td>0.724332</td>\n",
       "      <td>0.773774</td>\n",
       "      <td>0.748237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.982071</td>\n",
       "      <td>0.651236</td>\n",
       "      <td>0.804104</td>\n",
       "      <td>0.719641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.981456</td>\n",
       "      <td>0.605440</td>\n",
       "      <td>0.822936</td>\n",
       "      <td>0.697629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.978834</td>\n",
       "      <td>0.489812</td>\n",
       "      <td>0.846496</td>\n",
       "      <td>0.620551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.975857</td>\n",
       "      <td>0.380613</td>\n",
       "      <td>0.856253</td>\n",
       "      <td>0.526979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.966438</td>\n",
       "      <td>0.054896</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.103612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>0.966018</td>\n",
       "      <td>0.041048</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.078651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_accuracy  avg_recall  avg_precision  avg_f1_score\n",
       "0.50      0.982777    0.724332       0.773774      0.748237\n",
       "0.60      0.982071    0.651236       0.804104      0.719641\n",
       "0.70      0.981456    0.605440       0.822936      0.697629\n",
       "0.80      0.978834    0.489812       0.846496      0.620551\n",
       "0.85      0.975857    0.380613       0.856253      0.526979\n",
       "0.90      0.966438    0.054896       0.920398      0.103612\n",
       "0.95      0.966018    0.041048       0.936795      0.078651"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"PRECISION FOR DECISION TREE\")\n",
    "results_table[\"precision\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fifty-arbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE FOR DECISION TREE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.980736</td>\n",
       "      <td>0.768942</td>\n",
       "      <td>0.709954</td>\n",
       "      <td>0.738272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.980176</td>\n",
       "      <td>0.702572</td>\n",
       "      <td>0.727170</td>\n",
       "      <td>0.714659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.979429</td>\n",
       "      <td>0.597527</td>\n",
       "      <td>0.768771</td>\n",
       "      <td>0.672418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.977066</td>\n",
       "      <td>0.490406</td>\n",
       "      <td>0.778580</td>\n",
       "      <td>0.601772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.975374</td>\n",
       "      <td>0.422255</td>\n",
       "      <td>0.779868</td>\n",
       "      <td>0.547870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.969265</td>\n",
       "      <td>0.203165</td>\n",
       "      <td>0.735673</td>\n",
       "      <td>0.318400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_accuracy  avg_recall  avg_precision  avg_f1_score\n",
       "0.50      0.980736    0.768942       0.709954      0.738272\n",
       "0.60      0.980176    0.702572       0.727170      0.714659\n",
       "0.70      0.979429    0.597527       0.768771      0.672418\n",
       "0.80      0.977066    0.490406       0.778580      0.601772\n",
       "0.85      0.975374    0.422255       0.779868      0.547870\n",
       "0.90      0.969265    0.203165       0.735673      0.318400"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"F1_SCORE FOR DECISION TREE\")\n",
    "results_table[\"f1_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-staff",
   "metadata": {},
   "source": [
    "### Ricavo la sequenza di regole che hanno determinato la predizione di quei record che sono classificati come “QuasiPiena” con un certa soglia di probabilità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alternate-colors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 350)\n",
      "(78, 350)\n",
      "(4, 350)\n",
      "(2, 350)\n",
      "(144, 350)\n",
      "(65, 350)\n",
      "(294, 350)\n"
     ]
    }
   ],
   "source": [
    "prob_threshold = 90\n",
    "\n",
    "file1 = open(f'test_results/tuned_classifiers_with_threshold/Paths_DecisionTree_precision_30_5_({prob_threshold}%).txt', \"w\")\n",
    "file1.write(f'DECISION PATHS FOR DECISION TREE CLASSIFIER WITH THRESHOLD {prob_threshold}%:\\n\\n')\n",
    "\n",
    "for station_id in San_Fancisco_stations:\n",
    "    positive_records = pd.DataFrame()\n",
    "    model = load(f'./tuned_models/precision/DecisionTree/30_5/station{station_id}_tuned_model.joblib')\n",
    "    feature = model.tree_.feature\n",
    "    threshold = model.tree_.threshold\n",
    "    test_df = pd.read_csv(f'./datasets/{interval}_{window_width}/station{station_id}_test.csv')\n",
    "    y_test = test_df['status']\n",
    "    X_test = test_df.drop(columns=['status'])    \n",
    "#     plt.figure(figsize=(80,40))\n",
    "#     tree.plot_tree(model, fontsize=10, feature_names=X_test.columns, class_names=['N', 'QP'], label='all', filled=True, rounded=True)\n",
    "    \n",
    "    prediction_proba = model.predict_proba(X_test)\n",
    "    # prediction_proba è una matrice con due colonne: la prima colonna contiene le probabilità che il sample\n",
    "    # appartenga alla classe \"N\", il secondo contiene la probabilità di appartenenza alla classe \"QP\".\n",
    "    # quindi considerero la seconda colonna.\n",
    "\n",
    "    for index, el in enumerate(prediction_proba):\n",
    "        if el[1] >= prob_threshold/100: \n",
    "            positive_records = positive_records.append(X_test.iloc[[index]], ignore_index=True)\n",
    "    \n",
    "    if len (positive_records) >0:\n",
    "        \n",
    "        file1.write(f\"------------------------   STATION {station_id}   -----------------------------\\n\\n\")\n",
    "        print(positive_records.shape)\n",
    "        \n",
    "        for sample_id, row in positive_records.iterrows():\n",
    "            node_indicator = model.decision_path(positive_records)\n",
    "            leaf_id = model.apply(positive_records)\n",
    "            \n",
    "            # obtain ids of the nodes `sample_id` goes through, i.e., row `sample_id`\n",
    "            node_index = node_indicator.indices[\n",
    "                node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]\n",
    "            ]\n",
    "\n",
    "            file1.write(\"Regole usate per predire il record {id}:\\n\".format(id=sample_id))\n",
    "            for node_id in node_index:\n",
    "                # continue to the next node if it is a leaf node\n",
    "                if leaf_id[sample_id] == node_id:\n",
    "                    continue\n",
    "                \n",
    "                # check if value of the split feature for sample 0 is below threshold\n",
    "                if positive_records.iloc[sample_id].values[feature[node_id]] <= threshold[node_id]:\n",
    "                    threshold_sign = \"<=\"\n",
    "                else:\n",
    "                    threshold_sign = \">\"\n",
    "\n",
    "                file1.write(\n",
    "                    \"decision node {node} : ({feature} = {value}) \"\n",
    "                    \"{inequality} {threshold}\\n\".format(\n",
    "                        node=node_id,\n",
    "                        sample=sample_id,\n",
    "                        feature=positive_records.columns[feature[node_id]],\n",
    "                        value=positive_records.iloc[sample_id].values[feature[node_id]],\n",
    "                        inequality=threshold_sign,\n",
    "                        threshold=threshold[node_id],\n",
    "                    )\n",
    "                )\n",
    "            file1.write(\"\\n\")\n",
    "            \n",
    "file1.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip -r ../Zips/Classification.zip ../Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-progressive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-longitude",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
