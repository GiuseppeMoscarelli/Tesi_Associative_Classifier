{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "commercial-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reserved-tragedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "from datetime import datetime\n",
    "from pyspark.ml.fpm import PrefixSpan\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as F\n",
    "from math import sin, cos, sqrt, atan2, radians \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "support=0\n",
    "support_str = \"0\" #used for paths\n",
    "interval=15 #time window\n",
    "maxDelta=3 #how many spatial delta\n",
    "th=1 #distance\n",
    "window_size=3 #how many time delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "built-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT FILES\n",
    "inputPath  = \"file:///home/bigdata-01QYD/s270240/bike_sharing/filtered_status.csv\"\n",
    "STATION_PATH=\"file:///home/bigdata-01QYD/s270240/bike_sharing/station.csv\"\n",
    "#output files\n",
    "folder_path = f'./Results_extraction/Empty_almostEmpty/Empty_almostEmpty_{interval}_{int(th*1000)}_{support_str}({window_size}-{maxDelta})'\n",
    "output_file=f'{folder_path}/results_{int(th*1000)}_{support_str}_ordered_by_confidence.txt'\n",
    "output_file2=f'{folder_path}/results_{int(th*1000)}_{support_str}_QuasiVuota_Vuota_ordered_by_confidence.txt'\n",
    "output_file3=f'{folder_path}/results_{int(th*1000)}_{support_str}_diff_delta_ordered_by_confidence.txt'\n",
    "output_file4=f'{folder_path}/results_{int(th*1000)}_{support_str}_ordered_by_support.txt'\n",
    "output_file5=f'{folder_path}/results_{int(th*1000)}_{support_str}_QuasiVuota_Vuota_ordered_by_support.txt'\n",
    "output_file6=f'{folder_path}/results_{int(th*1000)}_{support_str}_diff_delta_ordered_by_support.txt'\n",
    "img_support=f'{window_size}-{maxDelta}-{int(th*1000)}-{support_str}.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indie-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF = spark.read.format(\"csv\")\\\n",
    ".option(\"delimiter\", \",\")\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"inferSchema\", True).load(inputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reliable-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF=inputDF.filter(\"bikes_available is not null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "local-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for these fields\n",
    "filteredDF = inputDF.filter(\"docks_available<>0 OR bikes_available<>0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "productive-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine if the station is empty or almost empty\n",
    "def stateFunction(docks_available,bikes_available):\n",
    "    if bikes_available==0:\n",
    "        return 1\n",
    "    elif (bikes_available==1 or bikes_available==2):\n",
    "        return 0\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ideal-remains",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.stateFunction(docks_available, bikes_available)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"state\", stateFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "educated-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInt(station):\n",
    "    return (station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "built-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.getInt(station)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"intValue\", getInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "balanced-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "getStatusDF = filteredDF.selectExpr(\"station_id\",\"time\", \"state(docks_available,bikes_available) as status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "separated-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getStatusDF.show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "headed-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter only empty or almost empty stations\n",
    "empty_almostEmpty=getStatusDF.filter(\"status==1  or status==0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "solid-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_almostEmpty_count = empty_almostEmpty.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "korean-trunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5998904386081785"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_almostEmpty_count/getStatusDF.count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "suited-tragedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+\n",
      "|summary|       station_id|             status|\n",
      "+-------+-----------------+-------------------+\n",
      "|  count|          3310905|            3310905|\n",
      "|   mean|50.45948887086763|0.15936579273642704|\n",
      "| stddev|21.19714002261148|0.36601690849561114|\n",
      "|    min|                2|                  0|\n",
      "|    max|               84|                  1|\n",
      "+-------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empty_almostEmpty.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "polyphonic-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a view\n",
    "empty_almostEmpty.createOrReplaceTempView(\"readings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "casual-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select station, year, month, day, hour, minute, status ordered by time\n",
    "ss=spark.sql(\"\"\"SELECT  station_id , YEAR(time) as year, MONTH(time) as month, DAY(time) as day, HOUR(time)as hour, MINUTE(time) as minute, status\n",
    "FROM readings\n",
    "GROUP BY station_id, year, month, day,hour,minute, status\n",
    "ORDER BY  station_id,year, month,day, hour,minute\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "institutional-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rdd and group into interval\n",
    "my_rdd=ss.rdd.map(tuple)\n",
    "rdd=my_rdd.map(lambda line: (line[0],line[1],line[2], line[3], line[4], int(line[5]/interval), line[6])).distinct()\n",
    "# rdd.collect()\n",
    "\n",
    "# [(4, 2014, 7, 25, 17, 0, '0'),\n",
    "#  (4, 2014, 8, 30, 19, 0, '0'),\n",
    "#  (36, 2015, 2, 19, 9, 0, '0'),\n",
    "#  (36, 2015, 7, 31, 3, 1, '0'),\n",
    "#  (37, 2013, 9, 10, 17, 1, '0'),\n",
    "#  (37, 2013, 10, 21, 15, 1, '0'),\n",
    "#  (37, 2013, 12, 11, 0, 0, '0'), ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "patent-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distinct stations to calculate distances\n",
    "id_stations=rdd.map(lambda line: line[0]).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "nearby-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_id_stations=id_stations.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "incomplete-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all stations\n",
    "#tot_id_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "equivalent-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain timestamp and info\n",
    "def getMap(line):\n",
    "    id_station=str(line[0])\n",
    "    year=int(line[1])\n",
    "    month=int(line[2])\n",
    "    day=int(line[3])\n",
    "    hour=int(line[4])\n",
    "    minute=int(line[5])   \n",
    "    timestamp= datetime(year,month, day, hour, minute)  \n",
    "    status=int(line[6])\n",
    "    if status==0:\n",
    "        status='QuasiVuota'\n",
    "    else:\n",
    "        status='Vuota'\n",
    "    info=id_station.split('.')[0]+'_'+status\n",
    "    return ( (timestamp,info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "revolutionary-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_map=rdd.map(getMap)\n",
    "# get_map.collect()\n",
    "\n",
    "# [(datetime.datetime(2014, 4, 18, 14, 1), '10_QuasiVuota'),\n",
    "#  (datetime.datetime(2014, 6, 12, 14, 1), '10_Vuota'),\n",
    "#  (datetime.datetime(2014, 7, 30, 13, 1), '10_Vuota'),\n",
    "#  (datetime.datetime(2015, 3, 17, 11, 1), '30_QuasiVuota'),\n",
    "#  (datetime.datetime(2014, 1, 1, 12, 0), '31_QuasiVuota'),\n",
    "#  (datetime.datetime(2014, 2, 20, 9, 0), '42_QuasiVuota'), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "popular-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each timestamp obtain info\n",
    "reduceK=get_map.reduceByKey(lambda l1,l2 :(l1+','+l2)).sortByKey()\n",
    "# reduceK.collect()\n",
    "\n",
    "# [(datetime.datetime(2013, 8, 29, 10, 0), '13_Vuota,67_Vuota,70_QuasiVuota,59_QuasiVuota,6_QuasiVuota,70_Vuota,67_QuasiVuota,2_QuasiVuota,7_Vuota,16_QuasiVuota,4_Vuota'),\n",
    "#  (datetime.datetime(2013, 8, 29, 10, 1), '73_QuasiVuota,7_QuasiVuota,13_QuasiVuota,69_QuasiVuota,13_Vuota,67_QuasiVuota,2_QuasiVuota,67_Vuota,4_Vuota,70_QuasiVuota,59_QuasiVuota,7_Vuota,16_QuasiVuota'),\n",
    "#  (datetime.datetime(2013, 8, 29, 11, 0), '67_QuasiVuota,73_QuasiVuota,70_QuasiVuota,67_Vuota,2_QuasiVuota,4_QuasiVuota,4_Vuota,16_QuasiVuota,69_QuasiVuota'),\n",
    "#  (datetime.datetime(2013, 8, 29, 11, 1), '73_QuasiVuota,69_QuasiVuota,67_QuasiVuota,16_QuasiVuota,2_QuasiVuota'), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beginning-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df=reduceK.toDF()\n",
    "#my_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "documentary-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.createOrReplaceTempView(\"view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "brief-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=spark.sql(\"\"\"SELECT ROW_NUMBER() OVER(ORDER BY _1,_2) as id ,_1, _2\n",
    "FROM view \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "printable-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifier of the timestamp, info\n",
    "rdd_scheme=s2.rdd.map(tuple).map(lambda line: (line[0], line[2]))\n",
    "# rdd_scheme.collect()\n",
    "\n",
    "# [(1, '13_Vuota,67_Vuota,70_QuasiVuota,59_QuasiVuota,6_QuasiVuota,70_Vuota,67_QuasiVuota,2_QuasiVuota,7_Vuota,16_QuasiVuota,4_Vuota'),\n",
    "#  (2, '73_QuasiVuota,7_QuasiVuota,13_QuasiVuota,69_QuasiVuota,13_Vuota,67_QuasiVuota,2_QuasiVuota,67_Vuota,4_Vuota,70_QuasiVuota,59_QuasiVuota,7_Vuota,16_QuasiVuota'),\n",
    "#  (3, '67_QuasiVuota,73_QuasiVuota,70_QuasiVuota,67_Vuota,2_QuasiVuota,4_QuasiVuota,4_Vuota,16_QuasiVuota,69_QuasiVuota'),\n",
    "#  (4, '73_QuasiVuota,69_QuasiVuota,67_QuasiVuota,16_QuasiVuota,2_QuasiVuota'),\n",
    "#  (5, '69_Vuota,16_QuasiVuota,2_QuasiVuota,73_QuasiVuota,69_QuasiVuota'),\n",
    "#  (6, '66_QuasiVuota,69_Vuota,16_QuasiVuota,73_QuasiVuota,68_QuasiVuota,2_QuasiVuota'),\n",
    "#  (7, '68_QuasiVuota,69_Vuota,2_QuasiVuota,66_QuasiVuota,76_Vuota,73_QuasiVuota,69_QuasiVuota,16_QuasiVuota'), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "civic-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain window, station-status\n",
    "def giveSplit(line):   \n",
    "    id_window=( int(line[0] ))\n",
    "    lista=[]    \n",
    "    counter=id_window    \n",
    "    while counter>=1:\n",
    "        lista.append(('Window '+str(counter),(line[1])))\n",
    "        counter=counter-1\n",
    "        if (id_window-counter)==window_size:\n",
    "            return lista  \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "official-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapData=rdd_scheme.flatMap(giveSplit)\n",
    "# mapData.collect()\n",
    "\n",
    "# [('Window 1', '13_Vuota,67_Vuota,70_QuasiVuota,59_QuasiVuota,6_QuasiVuota,70_Vuota,67_QuasiVuota,2_QuasiVuota,7_Vuota,16_QuasiVuota,4_Vuota'),\n",
    "#  ('Window 2', '73_QuasiVuota,7_QuasiVuota,13_QuasiVuota,69_QuasiVuota,13_Vuota,67_QuasiVuota,2_QuasiVuota,67_Vuota,4_Vuota,70_QuasiVuota,59_QuasiVuota,7_Vuota,16_QuasiVuota'),\n",
    "#  ('Window 1', '73_QuasiVuota,7_QuasiVuota,13_QuasiVuota,69_QuasiVuota,13_Vuota,67_QuasiVuota,2_QuasiVuota,67_Vuota,4_Vuota,70_QuasiVuota,59_QuasiVuota,7_Vuota,16_QuasiVuota'),\n",
    "#  ('Window 3', '67_QuasiVuota,73_QuasiVuota,70_QuasiVuota,67_Vuota,2_QuasiVuota,4_QuasiVuota,4_Vuota,16_QuasiVuota,69_QuasiVuota'),\n",
    "#  ('Window 2', '67_QuasiVuota,73_QuasiVuota,70_QuasiVuota,67_Vuota,2_QuasiVuota,4_QuasiVuota,4_Vuota,16_QuasiVuota,69_QuasiVuota'),, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "minor-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each window get all info\n",
    "all_keys=mapData.reduceByKey(lambda l1,l2:(l1+'-'+l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eastern-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_keys.collect()\n",
    "\n",
    "# [('Window 1',\n",
    "#   '13_Vuota,67_Vuota,70_QuasiVuota,59_QuasiVuota,6_QuasiVuota,70_Vuota,67_QuasiVuota,2_QuasiVuota,7_Vuota,16_QuasiVuota,4_Vuota-73_QuasiVuota,7_QuasiVuota,13_QuasiVuota,69_QuasiVuota,13_Vuota,67_QuasiVuota,2_QuasiVuota,67_Vuota,4_Vuota,70_QuasiVuota,59_QuasiVuota,7_Vuota,16_QuasiVuota-67_QuasiVuota,73_QuasiVuota,70_QuasiVuota,67_Vuota,2_QuasiVuota,4_QuasiVuota,4_Vuota,16_QuasiVuota,69_QuasiVuota'),\n",
    "#  ('Window 2',\n",
    "#   '73_QuasiVuota,7_QuasiVuota,13_QuasiVuota,69_QuasiVuota,13_Vuota,67_QuasiVuota,2_QuasiVuota,67_Vuota,4_Vuota,70_QuasiVuota,59_QuasiVuota,7_Vuota,16_QuasiVuota-67_QuasiVuota,73_QuasiVuota,70_QuasiVuota,67_Vuota,2_QuasiVuota,4_QuasiVuota,4_Vuota,16_QuasiVuota,69_QuasiVuota-73_QuasiVuota,69_QuasiVuota,67_QuasiVuota,16_QuasiVuota,2_QuasiVuota'),\n",
    "#  ('Window 3',\n",
    "#   '67_QuasiVuota,73_QuasiVuota,70_QuasiVuota,67_Vuota,2_QuasiVuota,4_QuasiVuota,4_Vuota,16_QuasiVuota,69_QuasiVuota-73_QuasiVuota,69_QuasiVuota,67_QuasiVuota,16_QuasiVuota,2_QuasiVuota-69_Vuota,16_QuasiVuota,2_QuasiVuota,73_QuasiVuota,69_QuasiVuota'),Window 4', '35_QuasiPiena,64_QuasiPiena,60_QuasiPiena-64_QuasiPiena,35_QuasiPiena,64_Piena,60_QuasiPiena-60_QuasiPiena,35_QuasiPiena,64_QuasiPiena,64_Piena'),\n",
    "#  ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "solid-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finestra temporale\n",
    "def reduceKeys(line):   \n",
    "    lista=[]\n",
    "    #lista.append(line[0])\n",
    "    line_split=line[1].split(\"-\")\n",
    "    #return line_split[0]\n",
    "    count=len(line_split)\n",
    "    tot=[]\n",
    "    for val in range(count):\n",
    "        li=[]\n",
    "        stations=line_split[val].split(',')\n",
    "        for st in stations:\n",
    "            all_string_st=st.split('_')[0]+'_'+'T'+str(val)+'_'+st.split('_')[1]\n",
    "            li.append(all_string_st)\n",
    "        tot.append(li)\n",
    "    lista.append((line[0],(tot))) \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "metric-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows=all_keys.flatMap(reduceKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "portable-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows.collect()\n",
    "\n",
    "# [('Window 1',\n",
    "#   [['13_T0_Vuota', '67_T0_Vuota', '70_T0_QuasiVuota', '59_T0_QuasiVuota', '6_T0_QuasiVuota', '70_T0_Vuota','67_T0_QuasiVuota','2_T0_QuasiVuota','7_T0_Vuota','16_T0_QuasiVuota','4_T0_Vuota'],\n",
    "#    ['73_T1_QuasiVuota','7_T1_QuasiVuota','13_T1_QuasiVuota','69_T1_QuasiVuota','13_T1_Vuota','67_T1_QuasiVuota','2_T1_QuasiVuota','67_T1_Vuota','4_T1_Vuota','70_T1_QuasiVuota','59_T1_QuasiVuota','7_T1_Vuota','16_T1_QuasiVuota'],\n",
    "#    ['67_T2_QuasiVuota','73_T2_QuasiVuota','70_T2_QuasiVuota','67_T2_Vuota','2_T2_QuasiVuota','4_T2_QuasiVuota','4_T2_Vuota','16_T2_QuasiVuota','69_T2_QuasiVuota']]),\n",
    "#  ('Window 2',\n",
    "#   [['73_T0_QuasiVuota','7_T0_QuasiVuota','13_T0_QuasiVuota','69_T0_QuasiVuota','13_T0_Vuota','67_T0_QuasiVuota','2_T0_QuasiVuota','67_T0_Vuota','4_T0_Vuota','70_T0_QuasiVuota','59_T0_QuasiVuota','7_T0_Vuota','16_T0_QuasiVuota'],\n",
    "#    ['67_T1_QuasiVuota','73_T1_QuasiVuota','70_T1_QuasiVuota','67_T1_Vuota','2_T1_QuasiVuota','4_T1_QuasiVuota','4_T1_Vuota','16_T1_QuasiVuota','69_T1_QuasiVuota'],\n",
    "#    ['73_T2_QuasiVuota','69_T2_QuasiVuota','67_T2_QuasiVuota','16_T2_QuasiVuota','2_T2_QuasiVuota']]), ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "attended-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save station file\n",
    "stationsDF = spark.read.format(\"csv\")\\\n",
    ".option(\"delimiter\", \",\")\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"inferSchema\", True).load(STATION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "informative-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only rows interested: only the used stations \n",
    "necessary_rows=stationsDF.filter(F.col(\"id\").isin(tot_id_stations)).sort(\"id\").rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "orange-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary_rows.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "finished-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get info of stations about coordinates and name\n",
    "coordinates=necessary_rows.map(lambda line: (line[0],(str(line[2])+','+str(line[3]))))\n",
    "names_stations=necessary_rows.map(lambda line: (line[0],line[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "given-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_coo=coordinates.collect()\n",
    "# list_coo\n",
    "\n",
    "# [(2, '37.329732,-121.90178200000001'),\n",
    "#  (3, '37.330698,-121.888979'),\n",
    "#  (4, '37.333988,-121.894902'),\n",
    "#  (5, '37.331415,-121.8932'), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "hungry-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary in which the key is the station and value is the info about coordinates\n",
    "dic_co=coordinates.collectAsMap()\n",
    "dic_coordinates=sc.broadcast(dic_co)\n",
    "#dic_coordinates.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "everyday-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to retrieve distance between 2 stations\n",
    "def getDistance(station1,station2):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0    \n",
    "    lat_a=float(station1.split(',')[0])\n",
    "    lat_b=float(station2.split(',')[0])\n",
    "    long_a=float(station1.split(',')[1])\n",
    "    long_b=float(station2.split(',')[1])\n",
    "    \n",
    "    lat1=radians(lat_a)\n",
    "    lat2=radians(lat_b)\n",
    "    lon1=radians(long_a)\n",
    "    lon2=radians(long_b)\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "marine-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#voc in which the key is a pair of stations and value is the distance\n",
    "voc_distances={}\n",
    "for i in range(len(list_coo)):\n",
    "    for j in range(i+1,len(list_coo)):\n",
    "        station1=list_coo[i][0]\n",
    "        station2=list_coo[j][0]\n",
    "        d_i=list_coo[i][1]\n",
    "        d_j=list_coo[j][1]\n",
    "        distance=getDistance(d_i,d_j)\n",
    "        id_stations=str(station1)+' '+str(station2)\n",
    "        voc_distances[id_stations]=distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "demographic-disney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1374454650255135"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_distances['2 3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "valid-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#voc_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "impaired-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applicazione “Delta Spaziale”\n",
    "def giveSpatialWindow(line):\n",
    "    lista=[]    \n",
    "    time0=line[1][0]    \n",
    "    dic={}\n",
    "    \n",
    "    count_windows=len(line[1])#tot windows\n",
    "\n",
    "    for station in time0:# only first window\n",
    "        act_station=int(station.split('_')[0])\n",
    "        #lista_station=[] \n",
    "        list_tmp=[]\n",
    "        \n",
    "        #for each window\n",
    "        for i,window in enumerate(line[1]):           \n",
    "            second_lista=[]\n",
    "            #for each element of a window\n",
    "            for all_el in window :\n",
    "                #second_lista=[]\n",
    "                act_all_el=int(all_el.split('_')[0])\n",
    "                state=all_el.split('_')[2]\n",
    "               \n",
    "                if act_station!=act_all_el:\n",
    "                    \n",
    "                    key=''\n",
    "                    if act_station<act_all_el:\n",
    "                        key=str(act_station)+' '+str(act_all_el)\n",
    "                    else:\n",
    "                        key=str(act_all_el)+' '+str(act_station)                    \n",
    "                    \n",
    "                    dist=voc_distances[key]\n",
    "                    if dist<=maxDelta*th:\n",
    "                        delta=0\n",
    "                        for d in range(1,maxDelta+1):\n",
    "                            if d*th>=dist:\n",
    "                                delta=d\n",
    "                                break                        \n",
    "                        string=state+'_'+'T'+str(i)+'_'+str(delta)\n",
    "                        second_lista.append(string)\n",
    "                else:\n",
    "                    string=state+'_'+'T'+str(i)+'_'+str(0)\n",
    "                    second_lista.append(string)\n",
    "                    \n",
    "            if len(second_lista)>0:\n",
    "                list_tmp.append(second_lista)\n",
    "        lista.append(((line[0]+'|'+str(act_station)),list_tmp))\n",
    "    \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "persistent-reading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278281\n"
     ]
    }
   ],
   "source": [
    "spatial_app=windows.flatMap(giveSpatialWindow)\n",
    "print(spatial_app.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "wireless-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial_app.collect()\n",
    "\n",
    "# [('Window 1|60',\n",
    "#   [['QuasiPiena_T0_0', 'Piena_T0_2', 'QuasiPiena_T0_2', 'QuasiPiena_T0_3'],\n",
    "#    ['Piena_T1_2', 'QuasiPiena_T1_3', 'QuasiPiena_T1_2', 'Piena_T1_3'],\n",
    "#    ['QuasiPiena_T2_3']]),\n",
    "#  ('Window 1|45',\n",
    "#   [['QuasiPiena_T0_2', 'Piena_T0_0', 'QuasiPiena_T0_0', 'QuasiPiena_T0_2'],\n",
    "#    ['Piena_T1_0', 'QuasiPiena_T1_2', 'QuasiPiena_T1_0', 'Piena_T1_2'],\n",
    "#    ['QuasiPiena_T2_2']]),\n",
    "#  ('Window 1|45',\n",
    "#   [['QuasiPiena_T0_2', 'Piena_T0_0', 'QuasiPiena_T0_0', 'QuasiPiena_T0_2'],\n",
    "#    ['Piena_T1_0', 'QuasiPiena_T1_2', 'QuasiPiena_T1_0', 'Piena_T1_2'],\n",
    "#    ['QuasiPiena_T2_2']]), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "accessory-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_seq(line):\n",
    "    true=line[1]\n",
    "    string=Row(sequence=true)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "accepted-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial=spatial_app.map(row_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "detailed-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278281\n"
     ]
    }
   ],
   "source": [
    "#create a dataframe\n",
    "df=spatial.toDF()\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "international-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "supports=[support]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "documentary-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|sequence                                                                                                                                                                                                                                                                                                                                                |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[QuasiVuota_T0_0, Vuota_T0_1, QuasiVuota_T0_2, Vuota_T0_1, Vuota_T0_1, QuasiVuota_T0_2], [QuasiVuota_T1_2, Vuota_T1_1, Vuota_T1_1, QuasiVuota_T1_0, QuasiVuota_T1_2, Vuota_T1_1], [QuasiVuota_T2_2, QuasiVuota_T2_1, QuasiVuota_T2_2, Vuota_T2_1, Vuota_T2_1, Vuota_T2_1], [Vuota_T3_1, Vuota_T3_1, QuasiVuota_T3_1, QuasiVuota_T3_2, QuasiVuota_T3_2]]|\n",
      "|[[QuasiVuota_T0_1, Vuota_T0_0, QuasiVuota_T0_2, Vuota_T0_1, Vuota_T0_1, QuasiVuota_T0_1], [QuasiVuota_T1_2, Vuota_T1_1, Vuota_T1_0, QuasiVuota_T1_1, QuasiVuota_T1_1, Vuota_T1_1], [QuasiVuota_T2_1, QuasiVuota_T2_0, QuasiVuota_T2_2, Vuota_T2_1, Vuota_T2_1, Vuota_T2_0], [Vuota_T3_1, Vuota_T3_1, QuasiVuota_T3_1, QuasiVuota_T3_1, QuasiVuota_T3_2]]|\n",
      "|[[QuasiVuota_T0_0, QuasiVuota_T0_1, Vuota_T0_3], [QuasiVuota_T1_0, QuasiVuota_T1_1, Vuota_T1_3, Vuota_T1_1, QuasiVuota_T1_3], [QuasiVuota_T2_0, QuasiVuota_T2_3, QuasiVuota_T2_3, QuasiVuota_T2_3, Vuota_T2_1], [QuasiVuota_T3_3, QuasiVuota_T3_1, QuasiVuota_T3_3, QuasiVuota_T3_3]]                                                                   |\n",
      "|[[QuasiVuota_T0_2, Vuota_T0_2, QuasiVuota_T0_0, Vuota_T0_2, Vuota_T0_1, QuasiVuota_T0_3], [QuasiVuota_T1_0, Vuota_T1_1, Vuota_T1_2, QuasiVuota_T1_2, QuasiVuota_T1_3, Vuota_T1_2], [QuasiVuota_T2_3, QuasiVuota_T2_2, QuasiVuota_T2_0, Vuota_T2_2, Vuota_T2_1, Vuota_T2_2], [Vuota_T3_1, Vuota_T3_2, QuasiVuota_T3_2, QuasiVuota_T3_3, QuasiVuota_T3_0]]|\n",
      "|[[QuasiVuota_T0_1, Vuota_T0_1, QuasiVuota_T0_2, Vuota_T0_0, Vuota_T0_1, QuasiVuota_T0_2], [QuasiVuota_T1_2, Vuota_T1_1, Vuota_T1_1, QuasiVuota_T1_1, QuasiVuota_T1_2, Vuota_T1_0], [QuasiVuota_T2_2, QuasiVuota_T2_1, QuasiVuota_T2_2, Vuota_T2_0, Vuota_T2_1, Vuota_T2_1], [Vuota_T3_1, Vuota_T3_0, QuasiVuota_T3_0, QuasiVuota_T3_2, QuasiVuota_T3_2]]|\n",
      "|[[QuasiVuota_T0_1, QuasiVuota_T0_0, Vuota_T0_2], [QuasiVuota_T1_1, QuasiVuota_T1_0, Vuota_T1_2, Vuota_T1_0, QuasiVuota_T1_2], [QuasiVuota_T2_1, QuasiVuota_T2_3, QuasiVuota_T2_2, QuasiVuota_T2_2, Vuota_T2_0], [QuasiVuota_T3_2, QuasiVuota_T3_0, QuasiVuota_T3_2, QuasiVuota_T3_3]]                                                                   |\n",
      "|[[QuasiVuota_T0_1, Vuota_T0_1, QuasiVuota_T0_1, Vuota_T0_1, Vuota_T0_0, QuasiVuota_T0_2], [QuasiVuota_T1_1, Vuota_T1_0, Vuota_T1_1, QuasiVuota_T1_1, QuasiVuota_T1_2, Vuota_T1_1], [QuasiVuota_T2_2, QuasiVuota_T2_1, QuasiVuota_T2_1, Vuota_T2_1, Vuota_T2_0, Vuota_T2_1], [Vuota_T3_0, Vuota_T3_1, QuasiVuota_T3_1, QuasiVuota_T3_2, QuasiVuota_T3_1]]|\n",
      "|[[QuasiVuota_T0_3, QuasiVuota_T0_2, Vuota_T0_0], [QuasiVuota_T1_3, QuasiVuota_T1_2, Vuota_T1_0, Vuota_T1_2, QuasiVuota_T1_0], [QuasiVuota_T2_3, QuasiVuota_T2_3, QuasiVuota_T2_1, QuasiVuota_T2_0, Vuota_T2_2], [QuasiVuota_T3_1, QuasiVuota_T3_2, QuasiVuota_T3_0, QuasiVuota_T3_3]]                                                                   |\n",
      "|[[QuasiVuota_T0_2, Vuota_T0_1, QuasiVuota_T0_3, Vuota_T0_2, Vuota_T0_2, QuasiVuota_T0_0], [QuasiVuota_T1_3, Vuota_T1_2, Vuota_T1_1, QuasiVuota_T1_2, QuasiVuota_T1_0, Vuota_T1_2], [QuasiVuota_T2_0, QuasiVuota_T2_1, QuasiVuota_T2_3, Vuota_T2_2, Vuota_T2_2, Vuota_T2_1], [Vuota_T3_2, Vuota_T3_2, QuasiVuota_T3_2, QuasiVuota_T3_0, QuasiVuota_T3_3]]|\n",
      "|[[QuasiVuota_T0_0, Vuota_T0_1, Vuota_T0_2, QuasiVuota_T0_2, QuasiVuota_T0_3, Vuota_T0_2], [QuasiVuota_T1_3, QuasiVuota_T1_2, QuasiVuota_T1_0, Vuota_T1_2, Vuota_T1_1, Vuota_T1_2], [Vuota_T2_1, Vuota_T2_2, QuasiVuota_T2_2, QuasiVuota_T2_3, QuasiVuota_T2_0], [QuasiVuota_T3_1, QuasiVuota_T3_3, Vuota_T3_1, QuasiVuota_T3_0]]                        |\n",
      "|[[QuasiVuota_T0_1, Vuota_T0_0, Vuota_T0_1, QuasiVuota_T0_1, QuasiVuota_T0_2, Vuota_T0_1], [QuasiVuota_T1_2, QuasiVuota_T1_1, QuasiVuota_T1_1, Vuota_T1_1, Vuota_T1_0, Vuota_T1_1], [Vuota_T2_0, Vuota_T2_1, QuasiVuota_T2_1, QuasiVuota_T2_2, QuasiVuota_T2_1], [QuasiVuota_T3_0, QuasiVuota_T3_2, Vuota_T3_0, QuasiVuota_T3_1]]                        |\n",
      "|[[QuasiVuota_T0_2, Vuota_T0_1, Vuota_T0_0, QuasiVuota_T0_1, QuasiVuota_T0_1, Vuota_T0_1], [QuasiVuota_T1_1, QuasiVuota_T1_0, QuasiVuota_T1_2, Vuota_T1_1, Vuota_T1_1, Vuota_T1_0], [Vuota_T2_1, Vuota_T2_1, QuasiVuota_T2_1, QuasiVuota_T2_1, QuasiVuota_T2_2], [QuasiVuota_T3_1, QuasiVuota_T3_1, Vuota_T3_1, QuasiVuota_T3_2]]                        |\n",
      "|[[QuasiVuota_T0_0, QuasiVuota_T0_1, Vuota_T0_3, Vuota_T0_1, QuasiVuota_T0_3], [QuasiVuota_T1_0, QuasiVuota_T1_3, QuasiVuota_T1_3, QuasiVuota_T1_3, Vuota_T1_1], [QuasiVuota_T2_3, QuasiVuota_T2_1, QuasiVuota_T2_3, QuasiVuota_T2_3], [QuasiVuota_T3_3, QuasiVuota_T3_3, QuasiVuota_T3_1, QuasiVuota_T3_3]]                                             |\n",
      "|[[QuasiVuota_T0_1, QuasiVuota_T0_0, Vuota_T0_2, Vuota_T0_0, QuasiVuota_T0_2], [QuasiVuota_T1_1, QuasiVuota_T1_3, QuasiVuota_T1_2, QuasiVuota_T1_2, Vuota_T1_0], [QuasiVuota_T2_2, QuasiVuota_T2_0, QuasiVuota_T2_2, QuasiVuota_T2_3], [QuasiVuota_T3_2, QuasiVuota_T3_2, QuasiVuota_T3_0, QuasiVuota_T3_3]]                                             |\n",
      "|[[QuasiVuota_T0_3, QuasiVuota_T0_2, Vuota_T0_0, Vuota_T0_2, QuasiVuota_T0_0], [QuasiVuota_T1_3, QuasiVuota_T1_3, QuasiVuota_T1_1, QuasiVuota_T1_0, Vuota_T1_2], [QuasiVuota_T2_1, QuasiVuota_T2_2, QuasiVuota_T2_0, QuasiVuota_T2_3], [QuasiVuota_T3_0, QuasiVuota_T3_1, QuasiVuota_T3_2, QuasiVuota_T3_3]]                                             |\n",
      "|[[QuasiVuota_T0_2, Vuota_T0_1, Vuota_T0_1, QuasiVuota_T0_0, QuasiVuota_T0_2, Vuota_T0_1], [QuasiVuota_T1_2, QuasiVuota_T1_1, QuasiVuota_T1_2, Vuota_T1_1, Vuota_T1_1, Vuota_T1_1], [Vuota_T2_1, Vuota_T2_1, QuasiVuota_T2_1, QuasiVuota_T2_2, QuasiVuota_T2_2], [QuasiVuota_T3_1, QuasiVuota_T3_2, Vuota_T3_1, QuasiVuota_T3_2]]                        |\n",
      "|[[QuasiVuota_T0_3, Vuota_T0_2, Vuota_T0_1, QuasiVuota_T0_2, QuasiVuota_T0_0, Vuota_T0_2], [QuasiVuota_T1_0, QuasiVuota_T1_1, QuasiVuota_T1_3, Vuota_T1_2, Vuota_T1_2, Vuota_T1_1], [Vuota_T2_2, Vuota_T2_2, QuasiVuota_T2_2, QuasiVuota_T2_0, QuasiVuota_T2_3], [QuasiVuota_T3_2, QuasiVuota_T3_0, Vuota_T3_2, QuasiVuota_T3_3]]                        |\n",
      "|[[QuasiVuota_T0_1, QuasiVuota_T0_0, Vuota_T0_2, Vuota_T0_0, QuasiVuota_T0_2], [QuasiVuota_T1_1, QuasiVuota_T1_3, QuasiVuota_T1_2, QuasiVuota_T1_2, Vuota_T1_0], [QuasiVuota_T2_2, QuasiVuota_T2_0, QuasiVuota_T2_2, QuasiVuota_T2_3], [QuasiVuota_T3_2, QuasiVuota_T3_2, QuasiVuota_T3_0, QuasiVuota_T3_3]]                                             |\n",
      "|[[QuasiVuota_T0_2, Vuota_T0_1, Vuota_T0_1, QuasiVuota_T0_1, QuasiVuota_T0_2, Vuota_T0_0], [QuasiVuota_T1_2, QuasiVuota_T1_1, QuasiVuota_T1_2, Vuota_T1_0, Vuota_T1_1, Vuota_T1_1], [Vuota_T2_1, Vuota_T2_0, QuasiVuota_T2_0, QuasiVuota_T2_2, QuasiVuota_T2_2], [QuasiVuota_T3_1, QuasiVuota_T3_2, Vuota_T3_1, QuasiVuota_T3_2]]                        |\n",
      "|[[QuasiVuota_T0_3, QuasiVuota_T0_2, Vuota_T0_0, Vuota_T0_2, QuasiVuota_T0_0], [QuasiVuota_T1_3, QuasiVuota_T1_3, QuasiVuota_T1_1, QuasiVuota_T1_0, Vuota_T1_2], [QuasiVuota_T2_1, QuasiVuota_T2_2, QuasiVuota_T2_0, QuasiVuota_T2_3], [QuasiVuota_T3_0, QuasiVuota_T3_1, QuasiVuota_T3_2, QuasiVuota_T3_3]]                                             |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefixspan to obtain sequence and frequence\n",
    "counter=[]\n",
    "for support in supports:\n",
    "    print(support)\n",
    "    prefixSpan = PrefixSpan(minSupport=support, maxPatternLength=5,\n",
    "                        maxLocalProjDBSize=5000)\n",
    "    prefix=prefixSpan.findFrequentSequentialPatterns(df)   \n",
    "    len_prefix=prefix.count()    \n",
    "    prefix.show(len_prefix,False)\n",
    "    counter.append(len_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=prefix.rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre.collect()\n",
    "\n",
    "# [([['QuasiVuota_T1_1']], 91278),\n",
    "#  ([['Vuota_T1_0']], 38790),\n",
    "#  ([['QuasiVuota_T0_3']], 63656),\n",
    "#  ([['Vuota_T0_1']], 44961),\n",
    "#  ([['Vuota_T0_0']], 53311),\n",
    "#  ([['Vuota_T2_0']], 27741), ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveSelected(line):\n",
    "    seq=line[0]\n",
    "    found=False   \n",
    "    for window in seq:\n",
    "        for el in window:\n",
    "            if 'T0' in el and '_0' in el:\n",
    "                found=True\n",
    "                break\n",
    "    return found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "giveT0=pre.filter(giveSelected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# giveT0.collect()\n",
    "\n",
    "# [([['Vuota_T0_0']], 53311),\n",
    "#  ([['QuasiVuota_T0_0']], 152819),\n",
    "#  ([['Vuota_T0_0', 'Vuota_T0_3']], 16267),\n",
    "#  ([['QuasiVuota_T0_0'], ['QuasiVuota_T1_2']], 90846),\n",
    "#  ([['QuasiVuota_T0_0'], ['Vuota_T1_0']], 30511),\n",
    "#  ([['QuasiVuota_T0_2', 'Vuota_T0_0']], 40779), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=giveT0.toDF().withColumnRenamed('_1','sequence')\n",
    "df2=df2.withColumnRenamed('_2','freq')#.show(len_prefix,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapValues(line):\n",
    "    seq=line[0]\n",
    "    final=''\n",
    "    #voc[seq]=line[1]\n",
    "    for i,window in enumerate(seq):\n",
    "        if i>0:\n",
    "            final+='-'\n",
    "        for j,el in enumerate(window):\n",
    "            if j>0:\n",
    "                final+=','\n",
    "            final+=el\n",
    "    final+=(';'+str(line[1])+';'+str(i))\n",
    "    return final  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapDict=giveT0.map(mapValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapDict.collect()\n",
    "\n",
    "# ['Vuota_T0_0;53311;0',\n",
    "#  'QuasiVuota_T0_0;152819;0',\n",
    "#  'Vuota_T0_0,Vuota_T0_3;16267;0',\n",
    "#  'QuasiVuota_T0_0-QuasiVuota_T1_2;90846;1',\n",
    "#  'QuasiVuota_T0_0-Vuota_T1_0;30511;1', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "li=mapDict.collect()\n",
    "voc={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in li:\n",
    "    splits=el.split(';')\n",
    "    voc[splits[0]]=int(splits[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voc\n",
    "\n",
    "# {'Vuota_T0_0': 53311,\n",
    "#  'QuasiVuota_T0_0': 152819,\n",
    "#  'Vuota_T0_0,Vuota_T0_3': 16267,\n",
    "#  'QuasiVuota_T0_0-QuasiVuota_T1_2': 90846,\n",
    "#  'QuasiVuota_T0_0-Vuota_T1_0': 30511, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_el_window=0\n",
    "for el in voc.keys():\n",
    "    flag_rep=False\n",
    "    windows=el.split('-')\n",
    "    for w in windows:\n",
    "        tot_items=len(w.split(','))\n",
    "        set_items=len(set(w.split(',')))\n",
    "        if tot_items!=set_items:\n",
    "            repeated_el_window+=1\n",
    "            break\n",
    "repeated_el_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_supports={}\n",
    "for el in voc.keys():    \n",
    "    if len(el.split('-'))>1:        \n",
    "        num=int(voc[el])       \n",
    "        string=''\n",
    "        tot=el.split('-')[:-1]\n",
    "        for k,station in enumerate(tot):\n",
    "            if k>0:\n",
    "                string+='-'\n",
    "            string+=station\n",
    "        #print(string)\n",
    "        den=int(voc[string])\n",
    "        voc_supports[el]=str(num/den)+' - '+str(voc[el])\n",
    "keys=list(voc_supports.keys())\n",
    "values=list(voc_supports.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort vocabulary by decreasing values and sort within each window\n",
    "for key in voc_supports:    \n",
    "    splitted=key.split('-')      \n",
    "    splitted.sort()\n",
    "# voc_supports = dict(sorted(voc_supports.items(), key=operator.itemgetter(1),reverse=True))\n",
    "voc_supports = dict(sorted(voc_supports.items(), \n",
    "                           key=lambda v: (float(v[1].split(' - ')[0]), int(v[1].split(' - ')[1])),\n",
    "                           reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(voc_supports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file='results_..._ordered_by_confidence.txt'\n",
    "file = open(output_file, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pattern=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in voc_supports:\n",
    "    key_list=[]\n",
    "    for e in el.split('-'):\n",
    "        key_list.append([e])\n",
    "    list_pattern.append([[key_list], [voc_supports[el]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write('Pattern, Confidence-Frequence'+'\\n')\n",
    "file.write(f'Total number of input patterns: {len(voc_supports)}'+'\\n')\n",
    "for el in list_pattern:  \n",
    "    file.write(str(el)+ '\\n')    \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file4='results_..._ordered_by_support.txt'\n",
    "file4 = open(output_file4, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order list fist by support and then by confidence\n",
    "list_ordered_by_support = sorted(list_pattern,\n",
    "                                 key=lambda v: (int(v[1][0].split(\" - \")[1]), float(v[1][0].split(\" - \")[0])),\n",
    "                                 reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "file4.write('Pattern, Confidence-Frequence'+'\\n')\n",
    "file4.write(f'Total number of input patterns: {len(voc_supports)}'+'\\n')\n",
    "for el in list_ordered_by_support:  \n",
    "    file4.write(str(el)+ '\\n')    \n",
    "file4.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_list=[]\n",
    "for i, j in zip(keys,values):\n",
    "    key_list=[]\n",
    "    for el in i.split('-'):\n",
    "        key_list.append([el])\n",
    "    tot_list.append([[key_list], [j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence=[]\n",
    "for el in values:\n",
    "    val=round(float(el.split(' - ')[0]),2)\n",
    "    confidence.append(val)\n",
    "#confidence    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(confidence)\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Number of patterns')\n",
    "plt.title(f'{maxDelta} threshold spaziale, {window_size} threshold temporale {th*1000} m e supporto {support}')\n",
    "plt.xlim(0.3,1)\n",
    "plt.savefig(img_support)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many min, max, avg items there are\n",
    "num_items=0\n",
    "num_freq_items=0\n",
    "min_items=sys.maxsize\n",
    "max_items=0\n",
    "avg_items=0\n",
    "\n",
    "num_freq_window=0\n",
    "tot_window=0\n",
    "num_patterns=0\n",
    "min_window=sys.maxsize\n",
    "max_window=0\n",
    "avg_window=0\n",
    "flag_vuota=False\n",
    "flag_quasi_vuota=False\n",
    "\n",
    "list_vuota_quasi_vuota=[]\n",
    "\n",
    "for key in voc_supports.keys():\n",
    "    flag_vuota=False\n",
    "    flag_quasi_vuota=False    \n",
    "    string=''\n",
    "    \n",
    "    #statistics for the windows\n",
    "    if '-' in key:\n",
    "        patterns=len(key.split('-'))\n",
    "        tot_window+=patterns      \n",
    "    else:\n",
    "        tot_window+=1\n",
    "        patterns=1\n",
    "    num_patterns+=1\n",
    "    \n",
    "    #statistics for the ìtems\n",
    "    if ('-' in key and ',' in key):\n",
    "        new_key=key       \n",
    "        new_key=new_key.replace(',', '-')               \n",
    "        items=new_key.split('-')\n",
    "        for el in items:\n",
    "            string+=el.split('_')[0]\n",
    "            if el.split('_')[0].startswith('Vuota') and flag_vuota==False:\n",
    "                flag_vuota=True\n",
    "            elif el.split('_')[0].startswith('QuasiVuota') and flag_quasi_vuota==False:\n",
    "                flag_quasi_vuota=True\n",
    "      \n",
    "       \n",
    "    elif ('-' in key):\n",
    "        items=key.split('-')\n",
    "        for el in items:\n",
    "            string+=el.split('_')[0]\n",
    "            if el.split('_')[0].startswith('Vuota') and flag_vuota==False:\n",
    "                flag_vuota=True\n",
    "            elif el.split('_')[0].startswith('QuasiVuota') and flag_quasi_vuota==False:\n",
    "                flag_quasi_vuota=True\n",
    "       \n",
    "    elif ( ',' in key):\n",
    "        items=key.split(',')\n",
    "        for el in items:\n",
    "            string+=el.split('_')[0]\n",
    "            if el.split('_')[0].startswith('Vuota') and flag_vuota==False:\n",
    "                flag_vuota=True\n",
    "            elif el.split('_')[0].startswith('QuasiVuota') and flag_quasi_vuota==False:\n",
    "                flag_quasi_vuota=True\n",
    "      \n",
    "    else:\n",
    "        items=list(key)\n",
    "        for el in items:\n",
    "            string+=el.split('_')[0]\n",
    "            if el.split('_')[0].startswith('Vuota') and flag_vuota==False:\n",
    "                flag_vuota=True\n",
    "            elif el.split('_')[0].startswith('QuasiVuota') and flag_quasi_vuota==False:\n",
    "                flag_quasi_vuota=True\n",
    "    if (flag_quasi_vuota==True and flag_vuota==True):       \n",
    "        key_list=[]            \n",
    "        for e in key.split('-'):\n",
    "            key_list.append([e])\n",
    "        list_vuota_quasi_vuota.append([[key_list], [voc_supports[key]]])\n",
    "\n",
    "    q_items=len(items) \n",
    "    if min_items>q_items:\n",
    "        min_items=q_items\n",
    "    if max_items<q_items:\n",
    "        max_items=q_items\n",
    "    freq=int(voc_supports[key].split('-')[1])\n",
    "    num_items+=freq \n",
    "    num_freq_items+=freq*q_items\n",
    "    \n",
    "    if min_window> patterns:\n",
    "        min_window=patterns\n",
    "    if max_window<patterns:\n",
    "        max_window=patterns    \n",
    "    num_freq_window+=freq*patterns  \n",
    "\n",
    "avg_window=0\n",
    "if num_items!=0:\n",
    "    avg_items=float(num_freq_items)/float(num_items)    \n",
    "    print(f'The average number of items is: {avg_items}')    \n",
    "    avg_window=float(num_freq_window)/ float(num_items)\n",
    "    print(f'The average number of windows is: {avg_window}')\n",
    "else:\n",
    "    print(f'The average number of windows is: {avg_window}')\n",
    "    \n",
    "print(f'The minimum number of items is: {min_items}')\n",
    "print(f'The maximum number of items is: {max_items}')\n",
    "print(f'The minimum number of windows is: {min_window}')\n",
    "print(f'The maximum number of windows is: {max_window}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FILTER PATTERNS WITH AT LEAST 1 EVENT QUASI VUOTA AND 1 EVENT VUOTA ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file2='results_..._QuasiVuota_Vuota_ordered_by_confidence.txt'\n",
    "file2 = open(output_file2, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lung_Vuota_quasiVuota=0\n",
    "if len(list_vuota_quasi_vuota)!=0:\n",
    "    df_supports=sc.parallelize(list_vuota_quasi_vuota).toDF().withColumnRenamed('_1','sequence')\n",
    "    df_supports=df_supports.withColumnRenamed('_2','confidence-freq')\n",
    "    lung_vuota_quasi_vuota=df_supports.count() \n",
    "#     df_supports.show(lung_vuota_quasi_vuota,False)\n",
    "#     print(lung_vuota_quasi_vuota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_vuota_quasi_vuota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.write('Pattern, Confidence-Frequence'+'\\n')\n",
    "file2.write(f'Total number of input patterns: {len(list_vuota_quasi_vuota)}'+'\\n')\n",
    "if len(list_vuota_quasi_vuota)!=0:\n",
    "    for el in list_vuota_quasi_vuota:\n",
    "        #print(el)\n",
    "        file2.write(str(el)+'\\n')\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file5='results_1000_0_QuasiVuota_Vuota_ordered_by_support.txt'\n",
    "file5 = open(output_file5, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order list fist by support an then by confidence\n",
    "list_vuota_quasi_vuota_ordered_by_support = sorted(list_vuota_quasi_vuota,\n",
    "                                                   key=lambda v: (int(v[1][0].split(\" - \")[1]), float(v[1][0].split(\" - \")[0])),\n",
    "                                                   reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "file5.write('Pattern, Confidence-Frequence'+'\\n')\n",
    "file5.write(f'Total number of input patterns: {len(list_vuota_quasi_vuota_ordered_by_support)}'+'\\n')\n",
    "if len(list_vuota_quasi_vuota_ordered_by_support)!=0:\n",
    "    for el in list_vuota_quasi_vuota_ordered_by_support:\n",
    "        #print(el)\n",
    "        file5.write(str(el)+'\\n')\n",
    "file5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FILTER PATTERNS WITH AT LEAST 1 T0, DELTA S=0 AND AT LEAST 1 PATTERN WITH AT LEAST 1 PATTERN WITH DELTA S DIFFERENT FROM 0 AND DELTA T DIFFERENT FROM 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_influenze=[]\n",
    "for el in voc_supports.keys():\n",
    "    delta_spaziale=False\n",
    "    if ('-' in el):\n",
    "        all_windows_list=el.split('-')\n",
    "        if ('T0_0' in all_windows_list[0] ):\n",
    "            for cons_window in all_windows_list[1::]:\n",
    "                if ',' in cons_window:\n",
    "                    for item in cons_window.split(','):                       \n",
    "                        act_delta=int(item.split('_')[2])\n",
    "                        if act_delta!=0:\n",
    "                            delta_spaziale=True\n",
    "    if delta_spaziale==True:        \n",
    "        key_list=[]            \n",
    "        for e in el.split('-'):\n",
    "            key_list.append([e])\n",
    "        list_influenze.append([[key_list], [voc_supports[el]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file3='results_..._diff_delta_ordered_by_confidence.txt'\n",
    "file3 = open(output_file3, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_different_time_space=0\n",
    "if len(list_influenze)!=0:\n",
    "    df_supports=sc.parallelize(list_influenze).toDF().withColumnRenamed('_1','sequence')\n",
    "    df_supports=df_supports.withColumnRenamed('_2','confidence-freq')\n",
    "    lung_different_time_space=df_supports.count() \n",
    "    #df_supports.show(lung_different_time_space,False)\n",
    "    #print(lung_different_time_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3.write('Pattern, Confidence-Frequence'+'\\n')\n",
    "file3.write(f'Total number of input patterns: {len(list_influenze)}'+'\\n')\n",
    "if len(list_influenze)!=0:\n",
    "    for el in list_influenze:       \n",
    "        file3.write(str(el)+'\\n')\n",
    "file3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file6='results_..._diff_delta_ordered_by_support.txt'\n",
    "file6 = open(output_file6, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order list first by support and then by confidence\n",
    "list_influenze_ordered_by_support = sorted(list_influenze,\n",
    "                                           key=lambda v: (int(v[1][0].split(\" - \")[1]), float(v[1][0].split(\" - \")[0])),\n",
    "                                           reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "file6.write('Pattern, Confidence-Frequence'+'\\n')\n",
    "file6.write(f'Total number of input patterns: {len(list_influenze_ordered_by_support)}'+'\\n')\n",
    "if len(list_influenze_ordered_by_support)!=0:\n",
    "    for el in list_influenze_ordered_by_support:       \n",
    "        file6.write(str(el)+'\\n')\n",
    "file6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The number of patterns in the pre-filter is: {len_prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The number of items after the filter with at least 2 windows and at least a T0 and delta 0 is: {len(voc_supports)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('STATISTICS about sequences with at least 2 windows_T0_delta0')\n",
    "print(f'The average number of windows is: {avg_window}')\n",
    "print(f'The minimum number of windows is: {min_window}')\n",
    "print(f'The maximum number of windows is: {max_window}')\n",
    "print(f'The average number of items is: {avg_items}')\n",
    "print(f'The minimum number of items is: {min_items}')\n",
    "print(f'The maximum number of items is: {max_items}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The number of patterns in which there is at least one item that repeats within a window is: {repeated_el_window} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The number of patterns with at least 1 event QuasiVuota and 1 event Vuota is: {lung_vuota_quasi_vuota}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-library",
   "metadata": {},
   "outputs": [],
   "source": [
    " print(f'The number of patterns with at least 1 T0, DELTA S=0 and at least 1 pattern with at least 1 pattern with DELTA S different from 0 and DELTA T different from 0 is: {lung_different_time_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'The time of execution is: {end-start} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-ozone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
