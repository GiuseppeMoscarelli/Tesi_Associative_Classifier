{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cosmetic-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fiscal-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "from datetime import datetime\n",
    "from pyspark.ml.fpm import PrefixSpan\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as F\n",
    "from math import sin, cos, sqrt, atan2, radians \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "interval=15 #time window\n",
    "maxDelta=3 #how many spatial delta\n",
    "th=1 #distance\n",
    "window_size=3 #how many time delta\n",
    "support=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "primary-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILES\n",
    "inputPath  = \"file:///home/bigdata-01QYD/s270240/bike_sharing/filtered_status.csv\"\n",
    "STATION_PATH=\"file:///home/bigdata-01QYD/s270240/bike_sharing/station.csv\"\n",
    "#save file of first filter\n",
    "folder_path = f'./Results_extraction/Time_slots_Full_almostFull/Time_slots_Full_almostFull_{interval}_{int(th*1000)}_{support_str}({window_size}-{maxDelta})'\n",
    "output_file_conf1=f'{folder_path}/results_6-10_ordered_by_confidence.txt'\n",
    "output_file_conf2=f'{folder_path}/results_10-14_ordered_by_confidence.txt'\n",
    "output_file_conf3=f'{folder_path}/results_14-17_ordered_by_confidence.txt'\n",
    "output_file_conf4=f'{folder_path}/results_17-20_ordered_by_confidence.txt'\n",
    "output_file_conf5=f'{folder_path}/results_20-24_ordered_by_confidence.txt'\n",
    "output_file_conf6=f'{folder_path}/results_0-6_ordered_by_confidence.txt'\n",
    "\n",
    "output_file_sup1=f'{folder_path}/results_6-10_ordered_by_support.txt'\n",
    "output_file_sup2=f'{folder_path}/results_10-14_ordered_by_support.txt'\n",
    "output_file_sup3=f'{folder_path}/results_14-17_ordered_by_support.txt'\n",
    "output_file_sup4=f'{folder_path}/results_17-20_ordered_by_support.txt'\n",
    "output_file_sup5=f'{folder_path}/results_20-24_ordered_by_support.txt'\n",
    "output_file_sup6=f'{folder_path}/results_0-6_ordered_by_support.txt'\n",
    "\n",
    "img_confidence1=f'{folder_path}/6-10_(4-3)_0.jpg'\n",
    "img_confidence2=f'{folder_path}/10-14_(4-3)_0.jpg'\n",
    "img_confidence3=f'{folder_path}/14-17_(4-3)_0.jpg'\n",
    "img_confidence4=f'{folder_path}/17-20_(4-3)_0.jpg'\n",
    "img_confidence5=f'{folder_path}/20-24_(4-3)_0.jpg'\n",
    "img_confidence6=f'{folder_path}/0-6_(4-3)_0.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "sharp-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF = spark.read.format(\"csv\")\\\n",
    ".option(\"delimiter\", \",\")\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"inferSchema\", True).load(inputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "middle-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF=inputDF.filter(\"bikes_available is not null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "arctic-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "interval=15 #time window\n",
    "maxDelta=3 #how many delta\n",
    "th=1 #distance\n",
    "window_size=4 #window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "occupational-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for these fields\n",
    "filteredDF = inputDF.filter(\"docks_available<>0 OR bikes_available<>0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "metropolitan-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine if the station is full or almost full\n",
    "def stateFunction(docks_available,bikes_available):\n",
    "    if docks_available==0:\n",
    "        return 1\n",
    "    elif (docks_available==1 or docks_available==2):\n",
    "        return 0\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "detected-spectacular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.stateFunction(docks_available, bikes_available)>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"state\", stateFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "unlimited-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInt(station):\n",
    "    return (station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "strong-convertible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.getInt(station)>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"intValue\", getInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "better-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "getStatusDF = filteredDF.selectExpr(\"station_id\",\"time\", \"state(docks_available,bikes_available) as status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "special-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getStatusDF.show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "rational-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter only full or almost full stations\n",
    "full_almostFull=getStatusDF.filter(\"status==1  or status==0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "organizational-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_almostFull_count = full_almostFull.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "outdoor-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.269968522286907"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_almostFull_count/getStatusDF.count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "harmful-variance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+\n",
      "|summary|        station_id|             status|\n",
      "+-------+------------------+-------------------+\n",
      "|  count|           2353655|            2353655|\n",
      "|   mean| 48.67931493783074|0.13855811493188255|\n",
      "| stddev|22.194133181275003| 0.3454848975439323|\n",
      "|    min|                 2|                  0|\n",
      "|    max|                84|                  1|\n",
      "+-------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_almostFull.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "humanitarian-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a view\n",
    "full_almostFull.createOrReplaceTempView(\"readings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "occupational-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select station, year, month, day, hour, minute, status ordered by time\n",
    "ss=spark.sql(\"\"\"SELECT  station_id , YEAR(time) as year, MONTH(time) as month, DAY(time) as day, HOUR(time)as hour, MINUTE(time) as minute, status\n",
    "FROM readings\n",
    "GROUP BY station_id, year, month, day,hour,minute, status\n",
    "ORDER BY  station_id,year, month,day, hour,minute\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "premium-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rdd and group into interval\n",
    "my_rdd=ss.rdd.map(tuple)\n",
    "rdd=my_rdd.map(lambda line: (line[0],line[1],line[2], line[3], line[4], int(line[5]/interval), line[6])).distinct()\n",
    "# rdd.collect()\n",
    "\n",
    "# [(4, 2014, 7, 25, 17, 0, '0'),\n",
    "#  (4, 2014, 8, 30, 19, 0, '0'),\n",
    "#  (36, 2015, 2, 19, 9, 0, '0'),\n",
    "#  (36, 2015, 7, 31, 3, 1, '0'),\n",
    "#  (37, 2013, 9, 10, 17, 1, '0'),\n",
    "#  (37, 2013, 10, 21, 15, 1, '0'),\n",
    "#  (37, 2013, 12, 11, 0, 0, '0'), ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "accepting-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distinct stations to calculate distances\n",
    "id_stations=rdd.map(lambda line: line[0]).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "relative-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_id_stations=id_stations.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "focal-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all stations\n",
    "#tot_id_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "negative-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain timestamp and info\n",
    "def getMap(line):\n",
    "    id_station=str(line[0])\n",
    "    year=int(line[1])\n",
    "    month=int(line[2])\n",
    "    day=int(line[3])\n",
    "    hour=int(line[4])\n",
    "    minute=int(line[5])   \n",
    "    timestamp= datetime(year,month, day, hour, minute)  \n",
    "    status=int(line[6])\n",
    "    if status==0:\n",
    "        status='QuasiPiena'\n",
    "    else:\n",
    "        status='Piena'\n",
    "    info=id_station.split('.')[0]+'_'+status\n",
    "    return ( (timestamp,info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "frozen-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_map=rdd.map(getMap)\n",
    "# get_map.collect()\n",
    "\n",
    "# [(datetime.datetime(2015, 5, 24, 19, 1), '3_QuasiPiena'),\n",
    "#  (datetime.datetime(2015, 7, 22, 12, 0), '3_QuasiPiena'),\n",
    "#  (datetime.datetime(2015, 8, 25, 17, 1), '3_QuasiPiena'),\n",
    "#  (datetime.datetime(2015, 8, 25, 18, 0), '3_QuasiPiena'),\n",
    "#  (datetime.datetime(2014, 12, 28, 17, 0), '36_QuasiPiena'),\n",
    "#  (datetime.datetime(2015, 2, 23, 21, 0), '36_QuasiPiena'), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "amber-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each timestamp obtain info\n",
    "reduceK=get_map.reduceByKey(lambda l1,l2 :(l1+','+l2)).sortByKey()\n",
    "# reduceK.collect()\n",
    "\n",
    "# [(datetime.datetime(2013, 8, 29, 10, 1), '45_Piena,60_QuasiPiena,64_QuasiPiena,45_QuasiPiena'),\n",
    "#  (datetime.datetime(2013, 8, 29, 11, 0), '45_Piena,64_QuasiPiena,45_QuasiPiena,64_Piena'),\n",
    "#  (datetime.datetime(2013, 8, 29, 11, 1), '35_QuasiPiena,64_QuasiPiena'),\n",
    "#  (datetime.datetime(2013, 8, 29, 12, 0), '64_QuasiPiena,60_QuasiPiena,35_QuasiPiena'),\n",
    "#  (datetime.datetime(2013, 8, 29, 12, 1), '64_Piena,35_QuasiPiena,60_QuasiPiena,64_QuasiPiena'), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "circular-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide rdd in different time slots\n",
    "slot1= reduceK.filter(lambda line : line[0].hour >=6 and line[0].hour<10)\n",
    "slot2= reduceK.filter(lambda line : line[0].hour >=10 and line[0].hour<14)\n",
    "slot3= reduceK.filter(lambda line : line[0].hour >=14 and line[0].hour<17)\n",
    "slot4= reduceK.filter(lambda line : line[0].hour >=17 and line[0].hour<20)\n",
    "slot5= reduceK.filter(lambda line : line[0].hour >=20 and line[0].hour<=23)\n",
    "slot6= reduceK.filter(lambda line : line[0].hour >=0 and line[0].hour<6)\n",
    "\n",
    "#create a list contaning all slots rdd\n",
    "slots = [slot1, slot2, slot3, slot4, slot5, slot6]\n",
    "\n",
    "# slots[0].collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "vertical-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df_list =[]\n",
    "\n",
    "for slot in slots:\n",
    "    my_df_list.append(slot.toDF())\n",
    "\n",
    "# my_df_list[0].collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "hidden-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, my_df in enumerate(my_df_list):\n",
    "    my_df.createOrReplaceTempView(f\"view{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "executive-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_rows_list = []\n",
    "for i in range(0,len(my_df_list)):\n",
    "    s2 = spark.sql(f\"\"\"SELECT ROW_NUMBER() OVER(ORDER BY _1,_2) as id ,_1, _2\n",
    "                FROM view{i} \"\"\")\n",
    "    add_rows_list.append(s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "synthetic-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifier of the timestamp, info\n",
    "rdd_scheme_list = []\n",
    "for s2 in add_rows_list:\n",
    "    rdd_scheme=s2.rdd.map(tuple).map(lambda line: (line[0], line[2]))\n",
    "    rdd_scheme_list.append(rdd_scheme)\n",
    "\n",
    "# rdd_scheme_list[0].collect()\n",
    "\n",
    "# [(1, '66_QuasiPiena,72_QuasiPiena,10_QuasiPiena,46_QuasiPiena,64_QuasiPiena'),\n",
    "#  (2, '64_QuasiPiena,10_QuasiPiena,46_QuasiPiena,72_QuasiPiena'),\n",
    "#  (3, '46_QuasiPiena,64_QuasiPiena,10_QuasiPiena'),\n",
    "#  (4, '10_QuasiPiena,64_QuasiPiena,46_QuasiPiena,60_QuasiPiena'),\n",
    "#  (5, '64_QuasiPiena,64_Piena,10_QuasiPiena,60_QuasiPiena,46_QuasiPiena'),, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "victorian-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain window, station-status\n",
    "def giveSplit(line):   \n",
    "    id_window=( int(line[0] ))\n",
    "    lista=[]    \n",
    "    counter=id_window    \n",
    "    while counter>=1:\n",
    "        lista.append(('Window '+str(counter),(line[1])))\n",
    "        counter=counter-1\n",
    "        if (id_window-counter)==window_size:\n",
    "            return lista  \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "metropolitan-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapData_list = []\n",
    "\n",
    "for rdd_scheme in rdd_scheme_list:\n",
    "    mapData=rdd_scheme.flatMap(giveSplit)\n",
    "    mapData_list.append(mapData)\n",
    "\n",
    "    \n",
    "# mapData_list[0].collect()\n",
    "\n",
    "# [('Window 1', '66_QuasiPiena,72_QuasiPiena,10_QuasiPiena,46_QuasiPiena,64_QuasiPiena'),\n",
    "#  ('Window 2', '64_QuasiPiena,10_QuasiPiena,46_QuasiPiena,72_QuasiPiena'),\n",
    "#  ('Window 1', '64_QuasiPiena,10_QuasiPiena,46_QuasiPiena,72_QuasiPiena'),\n",
    "#  ('Window 3', '46_QuasiPiena,64_QuasiPiena,10_QuasiPiena'),\n",
    "#  ('Window 2', '46_QuasiPiena,64_QuasiPiena,10_QuasiPiena'),\n",
    "#  ('Window 1', '46_QuasiPiena,64_QuasiPiena,10_QuasiPiena'), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "disciplinary-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each window get all info\n",
    "all_keys_list = []\n",
    "\n",
    "for mapData in mapData_list:\n",
    "    all_keys=mapData.reduceByKey(lambda l1,l2:(l1+'-'+l2))    \n",
    "    all_keys_list.append(all_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "stylish-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_keys_list[0].collect()\n",
    "\n",
    "# [('Window 1',\n",
    "#   '66_QuasiPiena,72_QuasiPiena,10_QuasiPiena,46_QuasiPiena,64_QuasiPiena-64_QuasiPiena,10_QuasiPiena,46_QuasiPiena,72_QuasiPiena-46_QuasiPiena,64_QuasiPiena,10_QuasiPiena'),\n",
    "#  ('Window 2',\n",
    "#   '64_QuasiPiena,10_QuasiPiena,46_QuasiPiena,72_QuasiPiena-46_QuasiPiena,64_QuasiPiena,10_QuasiPiena-10_QuasiPiena,64_QuasiPiena,46_QuasiPiena,60_QuasiPiena'),\n",
    "#  ('Window 3',\n",
    "#   '46_QuasiPiena,64_QuasiPiena,10_QuasiPiena-10_QuasiPiena,64_QuasiPiena,46_QuasiPiena,60_QuasiPiena-64_QuasiPiena,64_Piena,10_QuasiPiena,60_QuasiPiena,46_QuasiPiena'),\n",
    "#  ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "personal-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finestra temporale\n",
    "def reduceKeys(line):   \n",
    "    lista=[]\n",
    "    #lista.append(line[0])\n",
    "    line_split=line[1].split(\"-\")\n",
    "    #return line_split[0]\n",
    "    count=len(line_split)\n",
    "    tot=[]\n",
    "    for val in range(count):\n",
    "        li=[]\n",
    "        stations=line_split[val].split(',')\n",
    "        for st in stations:\n",
    "            all_string_st=st.split('_')[0]+'_'+'T'+str(val)+'_'+st.split('_')[1]\n",
    "            li.append(all_string_st)\n",
    "        tot.append(li)\n",
    "    lista.append((line[0],(tot))) \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "assigned-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_list = []\n",
    "\n",
    "for all_keys in all_keys_list:\n",
    "    windows=all_keys.flatMap(reduceKeys)\n",
    "    windows_list.append(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "lyric-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows_list[0].collect()\n",
    "\n",
    "# [('Window 1',\n",
    "#   [['66_T0_QuasiPiena', '72_T0_QuasiPiena', '10_T0_QuasiPiena', '46_T0_QuasiPiena', '64_T0_QuasiPiena'],\n",
    "#    ['64_T1_QuasiPiena', '10_T1_QuasiPiena', '46_T1_QuasiPiena', '72_T1_QuasiPiena'],\n",
    "#    ['46_T2_QuasiPiena', '64_T2_QuasiPiena', '10_T2_QuasiPiena']]),\n",
    "#  ('Window 2',\n",
    "#   [['64_T0_QuasiPiena', '10_T0_QuasiPiena', '46_T0_QuasiPiena', '72_T0_QuasiPiena'],\n",
    "#    ['46_T1_QuasiPiena', '64_T1_QuasiPiena', '10_T1_QuasiPiena'],\n",
    "#    ['10_T2_QuasiPiena', '64_T2_QuasiPiena', '46_T2_QuasiPiena', '60_T2_QuasiPiena']]), ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "hearing-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save station file\n",
    "stationsDF = spark.read.format(\"csv\")\\\n",
    ".option(\"delimiter\", \",\")\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"inferSchema\", True).load(STATION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "covered-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only rows interested: only the used stations \n",
    "necessary_rows=stationsDF.filter(F.col(\"id\").isin(tot_id_stations)).sort(\"id\").rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "alien-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary_rows.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "labeled-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get info of stations about coordinates and name\n",
    "coordinates=necessary_rows.map(lambda line: (line[0],(str(line[2])+','+str(line[3]))))\n",
    "names_stations=necessary_rows.map(lambda line: (line[0],line[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "nearby-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_coo=coordinates.collect()\n",
    "# list_coo\n",
    "\n",
    "# [(2, '37.329732,-121.90178200000001'),\n",
    "#  (3, '37.330698,-121.888979'),\n",
    "#  (4, '37.333988,-121.894902'),\n",
    "#  (5, '37.331415,-121.8932'), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "theoretical-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary in which the key is the station and value is the info about coordinates\n",
    "dic_co=coordinates.collectAsMap()\n",
    "dic_coordinates=sc.broadcast(dic_co)\n",
    "#dic_coordinates.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "compressed-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to retrieve distance between 2 stations\n",
    "def getDistance(station1,station2):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0    \n",
    "    lat_a=float(station1.split(',')[0])\n",
    "    lat_b=float(station2.split(',')[0])\n",
    "    long_a=float(station1.split(',')[1])\n",
    "    long_b=float(station2.split(',')[1])\n",
    "    \n",
    "    lat1=radians(lat_a)\n",
    "    lat2=radians(lat_b)\n",
    "    lon1=radians(long_a)\n",
    "    lon2=radians(long_b)\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "broken-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "#voc in which the key is a pair of stations and value is the distance\n",
    "voc_distances={}\n",
    "for i in range(len(list_coo)):\n",
    "    for j in range(i+1,len(list_coo)):\n",
    "        station1=list_coo[i][0]\n",
    "        station2=list_coo[j][0]\n",
    "        d_i=list_coo[i][1]\n",
    "        d_j=list_coo[j][1]\n",
    "        distance=getDistance(d_i,d_j)\n",
    "        id_stations=str(station1)+' '+str(station2)\n",
    "        voc_distances[id_stations]=distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "wired-moscow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1374454650255135"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_distances['2 3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "planned-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "#voc_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "nervous-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applicazione “Delta Spaziale”\n",
    "def giveSpatialWindow(line):\n",
    "    lista=[]    \n",
    "    time0=line[1][0]    \n",
    "    dic={}\n",
    "    \n",
    "    count_windows=len(line[1])#tot windows\n",
    "\n",
    "    for station in time0:# only first window\n",
    "        act_station=int(station.split('_')[0])\n",
    "        #lista_station=[] \n",
    "        list_tmp=[]\n",
    "        \n",
    "        #for each window\n",
    "        for i,window in enumerate(line[1]):           \n",
    "            second_lista=[]\n",
    "            #for each element of a window\n",
    "            for all_el in window :\n",
    "                #second_lista=[]\n",
    "                act_all_el=int(all_el.split('_')[0])\n",
    "                state=all_el.split('_')[2]\n",
    "               \n",
    "                if act_station!=act_all_el:\n",
    "                    \n",
    "                    key=''\n",
    "                    if act_station<act_all_el:\n",
    "                        key=str(act_station)+' '+str(act_all_el)\n",
    "                    else:\n",
    "                        key=str(act_all_el)+' '+str(act_station)                    \n",
    "                    \n",
    "                    dist=voc_distances[key]\n",
    "                    if dist<=maxDelta*th:\n",
    "                        delta=0\n",
    "                        for d in range(1,maxDelta+1):\n",
    "                            if d*th>=dist:\n",
    "                                delta=d\n",
    "                                break                        \n",
    "                        string=state+'_'+'T'+str(i)+'_'+str(delta)\n",
    "                        second_lista.append(string)\n",
    "                else:\n",
    "                    string=state+'_'+'T'+str(i)+'_'+str(0)\n",
    "                    second_lista.append(string)\n",
    "                    \n",
    "            if len(second_lista)>0:\n",
    "                list_tmp.append(second_lista)\n",
    "        lista.append(((line[0]+'|'+str(act_station)),list_tmp))\n",
    "    \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "limiting-laundry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num elements in slot1: 37541\n",
      "num elements in slot2: 30134\n",
      "num elements in slot3: 24775\n",
      "num elements in slot4: 25157\n",
      "num elements in slot5: 31812\n",
      "num elements in slot6: 49824\n"
     ]
    }
   ],
   "source": [
    "spatial_app_list = []\n",
    "\n",
    "for i, windows in enumerate(windows_list):\n",
    "    spatial_app=windows.flatMap(giveSpatialWindow)\n",
    "    print(f\"num elements in slot{i+1}: {spatial_app.count()}\")\n",
    "    spatial_app_list.append(spatial_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "limiting-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial_app_list[0].collect()\n",
    "\n",
    "# [('Window 1|66',\n",
    "#   [['QuasiPiena_T0_0', 'QuasiPiena_T0_1', 'QuasiPiena_T0_3', 'QuasiPiena_T0_3'],\n",
    "#    ['QuasiPiena_T1_3', 'QuasiPiena_T1_3', 'QuasiPiena_T1_1'],\n",
    "#    ['QuasiPiena_T2_3', 'QuasiPiena_T2_3']]),\n",
    "#  ('Window 1|72',\n",
    "#   [['QuasiPiena_T0_1', 'QuasiPiena_T0_0', 'QuasiPiena_T0_2', 'QuasiPiena_T0_2'],\n",
    "#    ['QuasiPiena_T1_2', 'QuasiPiena_T1_2', 'QuasiPiena_T1_0'],\n",
    "#    ['QuasiPiena_T2_2', 'QuasiPiena_T2_2']]),\n",
    "#  ('Window 1|10',\n",
    "#   [['QuasiPiena_T0_0'], ['QuasiPiena_T1_0'], ['QuasiPiena_T2_0']]), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "preceding-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_seq(line):\n",
    "    true=line[1]\n",
    "    string=Row(sequence=true)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "apparent-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_list = []\n",
    "\n",
    "for spatial_app in spatial_app_list:\n",
    "    spatial=spatial_app.map(row_seq)\n",
    "    spatial_list.append(spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "retained-picking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num elements in df1: 37541\n",
      "num elements in df2: 30134\n",
      "num elements in df3: 24775\n",
      "num elements in df4: 25157\n",
      "num elements in df5: 31812\n",
      "num elements in df6: 49824\n"
     ]
    }
   ],
   "source": [
    "#create dataframes\n",
    "df_list = []\n",
    "\n",
    "for i, spatial in enumerate(spatial_list):\n",
    "    df=spatial.toDF()\n",
    "    print (f\"num elements in df{i+1}: {df.count()}\")\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "legislative-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|sequence                                                                                                                                                                                                                             |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[QuasiPiena_T0_0, QuasiPiena_T0_3, QuasiPiena_T0_1, QuasiPiena_T0_3], [QuasiPiena_T1_3, QuasiPiena_T1_3, QuasiPiena_T1_1], [QuasiPiena_T2_3, QuasiPiena_T2_1, QuasiPiena_T2_3], [QuasiPiena_T3_3, QuasiPiena_T3_3, QuasiPiena_T3_1]]|\n",
      "|[[QuasiPiena_T0_3, QuasiPiena_T0_0, QuasiPiena_T0_2, QuasiPiena_T0_2], [QuasiPiena_T1_2, QuasiPiena_T1_0, QuasiPiena_T1_2], [QuasiPiena_T2_2, QuasiPiena_T2_2, QuasiPiena_T2_0], [QuasiPiena_T3_2, QuasiPiena_T3_0, QuasiPiena_T3_2]]|\n",
      "|[[QuasiPiena_T0_1, QuasiPiena_T0_2, QuasiPiena_T0_0, QuasiPiena_T0_2], [QuasiPiena_T1_2, QuasiPiena_T1_2, QuasiPiena_T1_0], [QuasiPiena_T2_2, QuasiPiena_T2_0, QuasiPiena_T2_2], [QuasiPiena_T3_2, QuasiPiena_T3_2, QuasiPiena_T3_0]]|\n",
      "|[[QuasiPiena_T0_3, QuasiPiena_T0_2, QuasiPiena_T0_2, QuasiPiena_T0_0], [QuasiPiena_T1_0, QuasiPiena_T1_2, QuasiPiena_T1_2], [QuasiPiena_T2_0, QuasiPiena_T2_2, QuasiPiena_T2_2], [QuasiPiena_T3_0, QuasiPiena_T3_2, QuasiPiena_T3_2]]|\n",
      "|[[QuasiPiena_T0_0], [QuasiPiena_T1_0], [QuasiPiena_T2_0], [QuasiPiena_T3_0]]                                                                                                                                                         |\n",
      "|[[QuasiPiena_T0_0], [QuasiPiena_T1_0], [QuasiPiena_T2_0], [QuasiPiena_T3_0]]                                                                                                                                                         |\n",
      "|[[QuasiPiena_T0_0, QuasiPiena_T0_2, QuasiPiena_T0_2], [QuasiPiena_T1_0, QuasiPiena_T1_2, QuasiPiena_T1_2], [QuasiPiena_T2_0, QuasiPiena_T2_2, QuasiPiena_T2_2], [QuasiPiena_T3_2, QuasiPiena_T3_0]]                                  |\n",
      "|[[QuasiPiena_T0_2, QuasiPiena_T0_0, QuasiPiena_T0_2], [QuasiPiena_T1_2, QuasiPiena_T1_2, QuasiPiena_T1_0], [QuasiPiena_T2_2, QuasiPiena_T2_0, QuasiPiena_T2_2], [QuasiPiena_T3_0, QuasiPiena_T3_2]]                                  |\n",
      "|[[QuasiPiena_T0_2, QuasiPiena_T0_2, QuasiPiena_T0_0], [QuasiPiena_T1_2, QuasiPiena_T1_0, QuasiPiena_T1_2], [QuasiPiena_T2_2, QuasiPiena_T2_2, QuasiPiena_T2_0], [QuasiPiena_T3_2, QuasiPiena_T3_2]]                                  |\n",
      "|[[QuasiPiena_T0_0, QuasiPiena_T0_2, QuasiPiena_T0_2], [QuasiPiena_T1_0, QuasiPiena_T1_2, QuasiPiena_T1_2], [QuasiPiena_T2_2, QuasiPiena_T2_0], [QuasiPiena_T3_2, QuasiPiena_T3_0]]                                                   |\n",
      "|[[QuasiPiena_T0_0], [QuasiPiena_T1_0], [QuasiPiena_T2_0], [QuasiPiena_T3_0]]                                                                                                                                                         |\n",
      "|[[QuasiPiena_T0_2, QuasiPiena_T0_0, QuasiPiena_T0_2], [QuasiPiena_T1_2, QuasiPiena_T1_2, QuasiPiena_T1_0], [QuasiPiena_T2_2, QuasiPiena_T2_2], [QuasiPiena_T3_2, QuasiPiena_T3_2]]                                                   |\n",
      "|[[QuasiPiena_T0_2, QuasiPiena_T0_2, QuasiPiena_T0_0], [QuasiPiena_T1_2, QuasiPiena_T1_0, QuasiPiena_T1_2], [QuasiPiena_T2_0, QuasiPiena_T2_2], [QuasiPiena_T3_0, QuasiPiena_T3_2]]                                                   |\n",
      "|[[QuasiPiena_T0_0], [QuasiPiena_T1_0], [QuasiPiena_T2_0], [QuasiPiena_T3_0]]                                                                                                                                                         |\n",
      "|[[QuasiPiena_T0_0, QuasiPiena_T0_2, QuasiPiena_T0_2], [QuasiPiena_T1_2, QuasiPiena_T1_0], [QuasiPiena_T2_2, QuasiPiena_T2_0], [QuasiPiena_T3_2, QuasiPiena_T3_3, QuasiPiena_T3_0]]                                                   |\n",
      "|[[QuasiPiena_T0_2, QuasiPiena_T0_0, QuasiPiena_T0_2], [QuasiPiena_T1_0, QuasiPiena_T1_2], [QuasiPiena_T2_0, QuasiPiena_T2_2], [QuasiPiena_T3_0, QuasiPiena_T3_2, QuasiPiena_T3_2]]                                                   |\n",
      "|[[QuasiPiena_T0_2, QuasiPiena_T0_2, QuasiPiena_T0_0], [QuasiPiena_T1_2, QuasiPiena_T1_2], [QuasiPiena_T2_2, QuasiPiena_T2_2], [QuasiPiena_T3_2, QuasiPiena_T3_3, QuasiPiena_T3_2]]                                                   |\n",
      "|[[QuasiPiena_T0_0, QuasiPiena_T0_2], [QuasiPiena_T1_0, QuasiPiena_T1_2], [QuasiPiena_T2_0, QuasiPiena_T2_2, QuasiPiena_T2_2], [QuasiPiena_T3_0, QuasiPiena_T3_2, QuasiPiena_T3_2]]                                                   |\n",
      "|[[QuasiPiena_T0_0], [QuasiPiena_T1_0], [QuasiPiena_T2_0], [QuasiPiena_T3_0]]                                                                                                                                                         |\n",
      "|[[QuasiPiena_T0_2, QuasiPiena_T0_0], [QuasiPiena_T1_2, QuasiPiena_T1_0], [QuasiPiena_T2_2, QuasiPiena_T2_3, QuasiPiena_T2_0], [QuasiPiena_T3_2, QuasiPiena_T3_0, QuasiPiena_T3_3]]                                                   |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list[0].show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefixspan to obtain sequence and frequence\n",
    "prefix_list = []\n",
    "len_prefix_list = []\n",
    "for df in df_list:\n",
    "    print(support)\n",
    "    prefixSpan = PrefixSpan(minSupport=support, maxPatternLength=5,\n",
    "                        maxLocalProjDBSize=5000)\n",
    "    prefix=prefixSpan.findFrequentSequentialPatterns(df)   \n",
    "    prefix_list.append(prefix)\n",
    "    len_prefix=prefix.count()    \n",
    "    prefix.show(len_prefix,False)\n",
    "    len_prefix_list.append(len_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_prefix_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_list = []\n",
    "\n",
    "for prefix in prefix_list:\n",
    "    pre=prefix.rdd.map(tuple)\n",
    "    pre_list.append(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_list[0].collect()\n",
    "\n",
    "# [([['QuasiPiena_T2_1']], 10429),\n",
    "#  ([['Piena_T2_1']], 4075),\n",
    "#  ([['Piena_T0_0']], 8453),\n",
    "#  ([['Piena_T2_2']], 5160),\n",
    "#  ([['QuasiPiena_T2_3']], 6729),\n",
    "#  ([['Piena_T2_3']], 2302),\n",
    "#  ([['Piena_T0_2']], 5527),... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveSelected(line):\n",
    "    seq=line[0]\n",
    "    found=False   \n",
    "    for window in seq:\n",
    "        for el in window:\n",
    "            if 'T0' in el and '_0' in el:\n",
    "                found=True\n",
    "                break\n",
    "    return found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "giveT0_list = []\n",
    "\n",
    "for pre in pre_list:\n",
    "    giveT0=pre.filter(giveSelected)\n",
    "    giveT0_list.append(giveT0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# giveT0_list[0].collect()\n",
    "\n",
    "# [([['Piena_T0_0']], 8453),\n",
    "#  ([['QuasiPiena_T0_0']], 22452),\n",
    "#  ([['QuasiPiena_T0_0'], ['QuasiPiena_T2_2']], 11945),\n",
    "#  ([['QuasiPiena_T0_0', 'QuasiPiena_T0_1']], 10352),\n",
    "#  ([['QuasiPiena_T0_0'], ['Piena_T2_1']], 3941), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2=giveT0.toDF().withColumnRenamed('_1','sequence')\n",
    "# df2=df2.withColumnRenamed('_2','freq')#.show(len_prefix,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapValues(line):\n",
    "    seq=line[0]\n",
    "    final=''\n",
    "    #voc[seq]=line[1]\n",
    "    for i,window in enumerate(seq):\n",
    "        if i>0:\n",
    "            final+='-'\n",
    "        for j,el in enumerate(window):\n",
    "            if j>0:\n",
    "                final+=','\n",
    "            final+=el\n",
    "    final+=(';'+str(line[1])+';'+str(i))\n",
    "    return final  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapDict_list = []\n",
    "\n",
    "for giveT0 in giveT0_list:\n",
    "    mapDict=giveT0.map(mapValues)\n",
    "    mapDict_list.append(mapDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapDict_list[0].collect()\n",
    "\n",
    "# ['Piena_T0_0;8453;0',\n",
    "#  'QuasiPiena_T0_0;22452;0',\n",
    "#  'QuasiPiena_T0_0-QuasiPiena_T2_2;11945;1',\n",
    "#  'QuasiPiena_T0_0,QuasiPiena_T0_1;10352;0',\n",
    "#  'QuasiPiena_T0_0-Piena_T2_1;3941;1',\n",
    "#  'Piena_T0_0-Piena_T2_0;1773;1', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_list =[]\n",
    "\n",
    "for mapDict in mapDict_list:\n",
    "    li=mapDict.collect()\n",
    "    li_list.append(li)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_list = []\n",
    "for li in li_list:\n",
    "    voc={}\n",
    "    for el in li:\n",
    "        splits=el.split(';')\n",
    "        voc[splits[0]]=int(splits[1])\n",
    "    voc_list.append(voc)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voc_list[0]\n",
    "\n",
    "# {'Piena_T0_0': 8453,\n",
    "#  'QuasiPiena_T0_0': 22452,\n",
    "#  'QuasiPiena_T0_0-QuasiPiena_T2_2': 11945,\n",
    "#  'QuasiPiena_T0_0,QuasiPiena_T0_1': 10352,\n",
    "#  'QuasiPiena_T0_0-Piena_T2_1': 3941, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_list = []\n",
    "\n",
    "for voc in voc_list:\n",
    "    repeated_el_window=0\n",
    "    for el in voc.keys():\n",
    "        flag_rep=False\n",
    "        windows=el.split('-')\n",
    "        for w in windows:\n",
    "            tot_items=len(w.split(','))\n",
    "            set_items=len(set(w.split(',')))\n",
    "            if tot_items!=set_items:\n",
    "                repeated_el_window+=1\n",
    "                break\n",
    "    repeated_list.append(repeated_el_window)\n",
    "    \n",
    "repeated_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_supports_list = []\n",
    "keys_list = []\n",
    "values_list = []\n",
    "\n",
    "for voc in voc_list:\n",
    "    voc_supports={}\n",
    "    for el in voc.keys():    \n",
    "        if len(el.split('-'))>1:        \n",
    "            num=int(voc[el])       \n",
    "            string=''\n",
    "            tot=el.split('-')[:-1]\n",
    "            for k,station in enumerate(tot):\n",
    "                if k>0:\n",
    "                    string+='-'\n",
    "                string+=station\n",
    "            #print(string)\n",
    "            den=int(voc[string])\n",
    "            voc_supports[el]=str(num/den)+' - '+str(voc[el])\n",
    "    voc_supports_list.append(voc_supports)\n",
    "#     keys=list(voc_supports.keys())\n",
    "#     keys_list.append(keys)\n",
    "#     values=list(voc_supports.values())\n",
    "#     values_list.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sort vocabulary by decreasing values and sort within each window\n",
    "# for voc_supports in voc_supports_list:\n",
    "#     for key in voc_supports:    \n",
    "#         splitted=key.split('-')      \n",
    "#         splitted.sort()\n",
    "#     # voc_supports = dict(sorted(voc_supports.items(), key=operator.itemgetter(1),reverse=True))\n",
    "#     global voc_supports = dict(sorted(voc_supports.items(), \n",
    "#                                key=lambda v: (float(v[1].split(' - ')[0]), int(v[1].split(' - ')[1])),\n",
    "#                                reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voc_supports_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, voc_supports in enumerate(voc_supports_list):\n",
    "    \n",
    "    #sort vocabulary by decreasing values of confidence\n",
    "    voc_supports = dict(sorted(voc_supports.items(), \n",
    "                               key=lambda v: (float(v[1].split(' - ')[0]), int(v[1].split(' - ')[1])),\n",
    "                               reverse=True))\n",
    "    \n",
    "    #save file ordered by confidence\n",
    "    file = open(eval(\"output_file_conf\"+str(i+1)), \"w\")\n",
    "    list_pattern=[]\n",
    "    for el in voc_supports:\n",
    "        key_list=[]\n",
    "        for e in el.split('-'):\n",
    "            key_list.append([e])\n",
    "        list_pattern.append([[key_list], [voc_supports[el]]])\n",
    "    file.write('TIME SLOT: ' + eval(\"output_file_conf\"+str(i+1)).split('_')[1] + ' Pattern, Confidence-Frequence'+'\\n')\n",
    "    file.write(f'Total number of input patterns: {len(voc_supports)}'+'\\n')\n",
    "    for el in list_pattern:  \n",
    "        file.write(str(el)+ '\\n')    \n",
    "    file.close()\n",
    "    \n",
    "    #save file ordered by support\n",
    "    file1 = open(eval(\"output_file_sup\"+str(i+1)), \"w\")\n",
    "    #order list first by support and then by confidence\n",
    "    list_ordered_by_support = sorted(list_pattern,\n",
    "                                     key=lambda v: (int(v[1][0].split(\" - \")[1]), float(v[1][0].split(\" - \")[0])),\n",
    "                                     reverse=True)\n",
    "    file1.write('TIME SLOT: ' + eval(\"output_file_sup\"+str(i+1)).split('_')[1] + ' Pattern, Confidence-Frequence'+ '\\n')\n",
    "    file1.write(f'Total number of input patterns: {len(voc_supports)}'+'\\n')\n",
    "    for el in list_ordered_by_support:  \n",
    "        file1.write(str(el)+ '\\n')    \n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_list = []\n",
    "\n",
    "#save images\n",
    "for i, voc_supports in enumerate(voc_supports_list): \n",
    "    confidence=[]\n",
    "    for el in voc_supports.values():\n",
    "        val=round(float(el.split(' - ')[0]),2)\n",
    "        confidence.append(val)\n",
    "    plt.hist(confidence)\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Number of patterns')\n",
    "    plt.title('TIME SLOT: ' + eval(\"output_file_conf\"+str(i+1)).split('_')[1] + f', interval {interval} min, supporto {support} ({window_size}-{maxDelta})')\n",
    "    plt.xlim(0.3,1)\n",
    "    plt.savefig(eval(\"img_confidence\"+str(i+1)))\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'The time of execution is: {end-start} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-chassis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
