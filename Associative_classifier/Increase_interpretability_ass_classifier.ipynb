{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surprising-updating",
   "metadata": {},
   "source": [
    "In questo notebook considererò la configurazione \"almostFull_35match_30min_5_(40%-0)\" e andrò a salvare in un file i pattern verificati in un paio di situazioni in cui la predizione sarà \"QuasiPiena\" e quelli in un paio di situazione in cui la predizione sarà \"Normal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conservative-bearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from math import sin, cos, sqrt, atan2, radians \n",
    "from sklearn import tree, svm, linear_model, ensemble, neighbors, naive_bayes \n",
    "import dateutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "commercial-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_path = Path('../filtered_status.csv')\n",
    "stations_path = Path('../station.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consistent-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df = pd.read_csv(status_path, parse_dates=['time'])\n",
    "stations_df = pd.read_csv(stations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occupied-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "#il seguente vettore è stato ottenuto in analisi fatte precedentemente. \n",
    "SFancisco_stations = [39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, \n",
    "                      61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-injection",
   "metadata": {},
   "source": [
    "### Calcolo la distanza tra le diverse stazioni della città di San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respective-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to retrieve distance between 2 stations\n",
    "def getDistance(lat_a, long_a, lat_b, long_b):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0    \n",
    "    lat1=radians(lat_a)\n",
    "    lat2=radians(lat_b)\n",
    "    lon1=radians(long_a)\n",
    "    lon2=radians(long_b)\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "killing-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_stations_df = stations_df[stations_df[\"id\"].isin(SFancisco_stations)]\n",
    "coordinates_stations_df = coordinates_stations_df[[\"id\", \"lat\", \"long\"]]\n",
    "records = coordinates_stations_df.to_records(index=False)\n",
    "list_coo = list(records)\n",
    "# print(list_coo)\n",
    "\n",
    "voc_distances={}\n",
    "for i in range(len(list_coo)):\n",
    "    for j in range(i+1,len(list_coo)):\n",
    "        station1=list_coo[i][0]\n",
    "        station2=list_coo[j][0]\n",
    "        lat_i=float(list_coo[i][1])\n",
    "        long_i=float(list_coo[i][2])\n",
    "        lat_j=float(list_coo[j][1])\n",
    "        long_j=float(list_coo[j][2])\n",
    "        distance=getDistance(lat_i, long_i, lat_j, long_j)\n",
    "        id_stations=str(station1)+' '+str(station2)\n",
    "        voc_distances[id_stations]=distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "crucial-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voc_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "british-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_dictionary = {}\n",
    "\n",
    "for station_id in SFancisco_stations:\n",
    "    distance_dictionary[station_id] = []\n",
    "    \n",
    "    delta0_stations = []\n",
    "    delta1_stations = []\n",
    "    delta2_stations = []\n",
    "\n",
    "    for key in voc_distances.keys():\n",
    "        if str(station_id) in key:\n",
    "            distance = voc_distances[key]\n",
    "\n",
    "            if key.split(\" \")[0] == str(station_id):\n",
    "                other=key.split(\" \")[1]\n",
    "            elif key.split(\" \")[1] == str(station_id):\n",
    "                other=key.split(\" \")[0]\n",
    "            \n",
    "            if distance<=1:\n",
    "                delta0_stations.append(other)         \n",
    "            elif distance<=2:\n",
    "                delta1_stations.append(other)\n",
    "            elif distance<=3:\n",
    "                delta2_stations.append(other)\n",
    "        \n",
    "    distance_dictionary[station_id].append(list(delta0_stations))\n",
    "    distance_dictionary[station_id].append(list(delta1_stations))\n",
    "    distance_dictionary[station_id].append(list(delta2_stations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-dealing",
   "metadata": {},
   "source": [
    "### Testo i pattern estratti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "liquid-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametri considerati per la costruzione dei dataset della classificazione\n",
    "time_interval = 30\n",
    "window_width = 5\n",
    "\n",
    "#Parametri usati per l'estazione dei pattern\n",
    "space_interval = 1000\n",
    "\n",
    "#Parametri usati per il filtraggio dei pattern\n",
    "conf_threshold = 40 #valore intero (%)\n",
    "sup_threshold = 0\n",
    "\n",
    "#Flag utile a considerare soltanto i pattern contenenti esclusivamente QuasiPiena\n",
    "filter_normal = True\n",
    "\n",
    "#Numero di pattern da matchare\n",
    "num_tot_pat = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affiliated-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se considero soltanto i pattern contenenti soltanto QuasiPiena\n",
    "if filter_normal:\n",
    "    pattern_path = f\"./Results_extraction/{time_interval}min_{space_interval}m/filtered_results({conf_threshold}%-{sup_threshold})_StateChange_almostFull_{time_interval}_{space_interval}_0(3-3)_ordered_by_confidence.txt\"\n",
    "    output_path = f'Test_results/{time_interval}min/sample_matched_patterns/matched_patterns_almostFull_{num_tot_pat}match_{time_interval}min_{window_width}_({conf_threshold}%-{sup_threshold}).txt'\n",
    "else:\n",
    "    pattern_path = f\"./Results_extraction/{time_interval}min_{space_interval}m/filtered_results({conf_threshold}%-{sup_threshold})_StateChange_Normal_almostFull_{time_interval}_{space_interval}_0(3-3)_ordered_by_confidence.txt\"\n",
    "    output_path = f'Test_results/{time_interval}min/sample_matched_patterns/matched_patterns_Normal_almostFull_{num_tot_pat}match_{time_interval}min_{window_width}_({conf_threshold}%-{sup_threshold}).txt'\n",
    "    \n",
    "file = open(output_path, \"w\")\n",
    "file.write(f'MATCHED PATTERNS:\\n\\n')\n",
    "\n",
    "#considero una stazione che ha avuto nel test una precisione abbstanza alta (92%)\n",
    "station_id = 61 \n",
    "\n",
    "normal_situation = 0\n",
    "critic_situation = 0\n",
    "\n",
    "\n",
    "test_path = Path(f'../Traditional_classification/datasets/{time_interval}_{window_width}/station{station_id}_test.csv')\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "\n",
    "#itero le righe del test set\n",
    "for index, row in test_df.iterrows():\n",
    "    matched_pattern_list = []\n",
    "    num_pat_matched = 0\n",
    "    prediction = \"N\"\n",
    "\n",
    "    #apro il file ed itero su tutti i pattern\n",
    "    with open(pattern_path, \"r\") as ifile:\n",
    "        for line in ifile:\n",
    "            #elimino gli header del file\n",
    "            if \"[[[\" not in line:\n",
    "                continue\n",
    "\n",
    "            flag = '' # sarà usaro per la condizione di uscita se una regola non metcha\n",
    "\n",
    "            #Trasformo la linea testuale in una lista\n",
    "            line_list = ast.literal_eval(line)\n",
    "\n",
    "#             #Prelevo il conseguente\n",
    "#             last = line_list[0][0][-1]\n",
    "\n",
    "            #elimino il conseguente\n",
    "            prior = line_list[0][0][:-1]\n",
    "\n",
    "            #Prelevo l'ultimo elemento\n",
    "            last = prior[-1]\n",
    "\n",
    "            #Ricavo l'istante temporale dell'ultimo slot che corrisponderà all'istante 0 nella tabella del test set\n",
    "            curr_time_slot = int(last[0].split('_')[1][1])\n",
    "\n",
    "\n",
    "            #Itero gli slot di tempo precedenti al conseguente\n",
    "            for item in prior:\n",
    "#                 print(f\"1_{flag}\")\n",
    "\n",
    "                matched_neigh = 0\n",
    "\n",
    "                #controllo se è già stata settata la condizione di uscita\n",
    "                if flag == \"next_line\":\n",
    "                    break\n",
    "\n",
    "                #ricavo la stringa contenuta nell'i-esimo slot e la splitto per ottenere la lista dei controlli da fare\n",
    "                check_list = item[0].split(\",\")\n",
    "\n",
    "                #itero sulla lista contenuta nello stesso slot temporale\n",
    "                for el in check_list:\n",
    "#                     print(f\"2_{flag}\")\n",
    "                    #controllo se è già stato settata la condizione di uscita\n",
    "                    if flag == \"next_line\":\n",
    "                        break\n",
    "\n",
    "                    el_status = el.split('_')[0]\n",
    "                    el_time_slot = int(el.split('_')[1][1])\n",
    "                    el_space_slot = int(el.split('_')[2])     \n",
    "\n",
    "                    feature_time_slot = curr_time_slot - el_time_slot\n",
    "\n",
    "                    #se la stazione è quella di riferimento\n",
    "                    if el_space_slot == 0:\n",
    "\n",
    "                        #A partire da queste info costruisco la feature da andare a controllare\n",
    "                        feature_str = f\"docks_av_{station_id}_T{feature_time_slot}\"\n",
    "\n",
    "#                         print(feature_str)\n",
    "\n",
    "                        #Se la regola non è verificata, passo alla prossima\n",
    "                        if (el_status == \"QuasiPiena\" and row[feature_str] > 2) or (el_status == \"Normal\" and row[feature_str] <= 2):\n",
    "                            flag = \"next_line\"\n",
    "#                             print(f\"3_{flag}\")\n",
    "                            break\n",
    "\n",
    "\n",
    "                    #se invece si tratta di una delle stazioni vicine:\n",
    "                    else:\n",
    "                        neighbors = distance_dictionary[station_id][el_space_slot-1]\n",
    "                        for neigh_id in neighbors:\n",
    "                            #inizialmente lo stesso al caso negativo\n",
    "                            flag = \"next_line\"\n",
    "\n",
    "                            #se il vicino corrente ha già verificato la regola, passo al vicino successivo \n",
    "                            # (utile nei casi in cui si hanno piu regole nello stesso delta spaziale)\n",
    "                            if neigh_id == matched_neigh:\n",
    "                                continue\n",
    "\n",
    "                            feature_str = f\"docks_av_{neigh_id}_T{feature_time_slot}\"\n",
    "#                             print(feature_str)\n",
    "\n",
    "                            #se il vicino corrente non rispetta il pattern, passo al vicino successivo\n",
    "                            if (el_status == \"QuasiPiena\" and row[feature_str] > 2) or (el_status == \"Normal\" and row[feature_str] <= 2):\n",
    "                                continue\n",
    "\n",
    "                            #se invece viene trovato un vicino che rispetta il pattern, rimetto il flag ='' ed esco dal ciclo  \n",
    "                            flag=''\n",
    "                            matched_neigh= neigh_id\n",
    "                            break\n",
    "\n",
    "                        if flag == \"next_line\":\n",
    "                            break\n",
    "\n",
    "\n",
    "            #se a questo punto il flag non è stato settato a \"next_line\", vuol dire che nessuna delle condizioni sfavorevoli \n",
    "            # precedenti è stata verificata, quindi il pattern ha metchato. \n",
    "            if flag != \"next_line\":\n",
    "                #incremento il numero di pattern verificati\n",
    "                num_pat_matched +=1\n",
    "                matched_pattern_list.append(line)\n",
    "\n",
    "                #se il numero di pattern verificati è uguale al numero di pattern da verificare desiderato\n",
    "                if num_pat_matched == num_tot_pat: \n",
    "                    # Setto pred a \"QP\" ed esco\n",
    "                    prediction = \"QP\"\n",
    "    #                 print(f'PATTERN MATCHED NUM: {num_row}')\n",
    "                    break\n",
    "#     print (matched_pattern_list)\n",
    "#     print (prediction)\n",
    "    \n",
    "    if prediction == \"QP\":\n",
    "        critic_situation +=1\n",
    "        if critic_situation <= 2 :\n",
    "            file.write(f'Predicted status QUASI PIENA:\\n')\n",
    "            for pat in matched_pattern_list:\n",
    "                file.write(pat)\n",
    "            file.write('\\n')\n",
    "                \n",
    "    elif prediction == \"N\" and len(matched_pattern_list) >5:\n",
    "        normal_situation +=1\n",
    "        if normal_situation <= 2 :\n",
    "            file.write(f'Predicted status NORMAL:\\n')\n",
    "            for pat in matched_pattern_list:\n",
    "                file.write(pat)\n",
    "            file.write('\\n')\n",
    "    \n",
    "    if critic_situation>2 and normal_situation>2:\n",
    "        break\n",
    "            \n",
    "            \n",
    "#     y_pred.append(prediction)\n",
    "\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
