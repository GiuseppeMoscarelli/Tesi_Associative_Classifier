{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assigned-administration",
   "metadata": {},
   "source": [
    "Partendo dal notebook \"Testing_rules_multiple_match_Time_Slots\" apporto le modifiche necessarie affinchè venga considerato l'effettivo cambio di stato nella classificazione. Quindi prima di classificare un record del test set come QP, valuto prima se all'istante precedente la stazione si trovava effettivamente in uno stato diverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "entire-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from math import sin, cos, sqrt, atan2, radians \n",
    "from sklearn import tree, svm, linear_model, ensemble, neighbors, naive_bayes \n",
    "import dateutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boxed-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_path = Path('../filtered_status.csv')\n",
    "stations_path = Path('../station.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amber-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df = pd.read_csv(status_path, parse_dates=['time'])\n",
    "stations_df = pd.read_csv(stations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "downtown-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#il seguente vettore è stato ottenuto in analisi fatte precedentemente. \n",
    "SFancisco_stations = [39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, \n",
    "                      61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-restaurant",
   "metadata": {},
   "source": [
    "### Calcolo la distanza tra le diverse stazioni della città di San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atmospheric-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to retrieve distance between 2 stations\n",
    "def getDistance(lat_a, long_a, lat_b, long_b):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0    \n",
    "    lat1=radians(lat_a)\n",
    "    lat2=radians(lat_b)\n",
    "    lon1=radians(long_a)\n",
    "    lon2=radians(long_b)\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cleared-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_stations_df = stations_df[stations_df[\"id\"].isin(SFancisco_stations)]\n",
    "coordinates_stations_df = coordinates_stations_df[[\"id\", \"lat\", \"long\"]]\n",
    "records = coordinates_stations_df.to_records(index=False)\n",
    "list_coo = list(records)\n",
    "# print(list_coo)\n",
    "\n",
    "voc_distances={}\n",
    "for i in range(len(list_coo)):\n",
    "    for j in range(i+1,len(list_coo)):\n",
    "        station1=list_coo[i][0]\n",
    "        station2=list_coo[j][0]\n",
    "        lat_i=float(list_coo[i][1])\n",
    "        long_i=float(list_coo[i][2])\n",
    "        lat_j=float(list_coo[j][1])\n",
    "        long_j=float(list_coo[j][2])\n",
    "        distance=getDistance(lat_i, long_i, lat_j, long_j)\n",
    "        id_stations=str(station1)+' '+str(station2)\n",
    "        voc_distances[id_stations]=distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "anticipated-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voc_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "decreased-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_dictionary = {}\n",
    "\n",
    "\n",
    "for station_id in SFancisco_stations:\n",
    "    distance_dictionary[station_id] = []\n",
    "    \n",
    "    delta0_stations = []\n",
    "    delta1_stations = []\n",
    "    delta2_stations = []\n",
    "\n",
    "    for key in voc_distances.keys():\n",
    "        if str(station_id) in key:\n",
    "            distance = voc_distances[key]\n",
    "\n",
    "            if key.split(\" \")[0] == str(station_id):\n",
    "                other=key.split(\" \")[1]\n",
    "            elif key.split(\" \")[1] == str(station_id):\n",
    "                other=key.split(\" \")[0]\n",
    "            \n",
    "            if distance<=1:\n",
    "                delta0_stations.append(other)         \n",
    "            elif distance<=2:\n",
    "                delta1_stations.append(other)\n",
    "            elif distance<=3:\n",
    "                delta2_stations.append(other)\n",
    "        \n",
    "    distance_dictionary[station_id].append(list(delta0_stations))\n",
    "    distance_dictionary[station_id].append(list(delta1_stations))\n",
    "    distance_dictionary[station_id].append(list(delta2_stations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stunning-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Questo dizionario contiene come chiave tutte le stazioni e come valori corrisopondenti tre liste contenenti\n",
    "# le stazioni che distantano dalla stazione della chiave rispettivamente <1 km, tra 1 e  \n",
    "\n",
    "# distance_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "separate-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance_dictionary[63]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-probe",
   "metadata": {},
   "source": [
    "### Testo i pattern estratti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "academic-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametri considerati per la costruzione dei dataset della classificazione\n",
    "time_interval = 30\n",
    "window_width = 5\n",
    "\n",
    "#Parametri usati per l'estazione dei pattern\n",
    "space_interval = 1000\n",
    "\n",
    "#Parametri usati per il filtraggio dei pattern\n",
    "conf_threshold = 50 #valore intero (%)\n",
    "sup_threshold = 0\n",
    "\n",
    "#Flag utile a considerare soltanto i pattern contenenti esclusivamente QuasiPiena\n",
    "filter_normal = False\n",
    "\n",
    "#Numero di pattern da metchare\n",
    "num_tot_pat = 30\n",
    "\n",
    "#Lista di fasce temporali da considerare\n",
    "time_slots = [\n",
    "    \"0-6\", \n",
    "    \"6-10\", \n",
    "    \"10-14\", \n",
    "    \"14-17\", \n",
    "    \"17-20\", \n",
    "    \"20-24\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "grateful-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- TIME SLOT 0-6 ----\n",
      "\n",
      "AVERAGE VALUES FOR PATTERN TEST:\n",
      "Confusion matrix:\n",
      "[[73939 6]\n",
      "[3608 7]]\n",
      "tot_tp=7, tot_fn=3608, tot_fp=6, tot_tn=73939\n",
      "accuracy=0.9534038164002063; recall=0.0019363762102351315; precision=0.5384615384615384; f1_score=0.003858875413450937\n",
      "\n",
      "\n",
      "---- TIME SLOT 6-10 ----\n",
      "\n",
      "AVERAGE VALUES FOR PATTERN TEST:\n",
      "Confusion matrix:\n",
      "[[51837 0]\n",
      "[1678 0]]\n",
      "tot_tp=0, tot_fn=1678, tot_fp=0, tot_tn=51837\n",
      "accuracy=0.9686443053349528; recall=0.0; precision=0.0; f1_score=0.0\n",
      "\n",
      "\n",
      "---- TIME SLOT 10-14 ----\n",
      "\n",
      "AVERAGE VALUES FOR PATTERN TEST:\n",
      "Confusion matrix:\n",
      "[[52176 0]\n",
      "[1584 0]]\n",
      "tot_tp=0, tot_fn=1584, tot_fp=0, tot_tn=52176\n",
      "accuracy=0.9705357142857143; recall=0.0; precision=0.0; f1_score=0.0\n",
      "\n",
      "\n",
      "---- TIME SLOT 14-17 ----\n",
      "\n",
      "AVERAGE VALUES FOR PATTERN TEST:\n",
      "Confusion matrix:\n",
      "[[40604 0]\n",
      "[1011 0]]\n",
      "tot_tp=0, tot_fn=1011, tot_fp=0, tot_tn=40604\n",
      "accuracy=0.9757058752853538; recall=0.0; precision=0.0; f1_score=0.0\n",
      "\n",
      "\n",
      "---- TIME SLOT 17-20 ----\n",
      "\n",
      "AVERAGE VALUES FOR PATTERN TEST:\n",
      "Confusion matrix:\n",
      "[[40260 0]\n",
      "[1355 0]]\n",
      "tot_tp=0, tot_fn=1355, tot_fp=0, tot_tn=40260\n",
      "accuracy=0.9674396251351676; recall=0.0; precision=0.0; f1_score=0.0\n",
      "\n",
      "\n",
      "---- TIME SLOT 20-24 ----\n",
      "\n",
      "AVERAGE VALUES FOR PATTERN TEST:\n",
      "Confusion matrix:\n",
      "[[46074 1]\n",
      "[1840 0]]\n",
      "tot_tp=0, tot_fn=1840, tot_fp=1, tot_tn=46074\n",
      "accuracy=0.9615777940102265; recall=0.0; precision=0.0; f1_score=0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for slot in time_slots:\n",
    "    print(f\"---- TIME SLOT {slot} ----\\n\")\n",
    "    #Se considero soltanto i pattern contenenti soltanto QuasiPiena\n",
    "    if filter_normal:\n",
    "        pattern_path = f\"./Results_extraction/{time_interval}min_{space_interval}m/Time_slots/filtered_results_{slot}_({conf_threshold}%-{sup_threshold})_StateChange_almostFull_{time_interval}_{space_interval}_0(3-3)_ordered_by_confidence.txt\"\n",
    "        output_path = f'Test_results/{time_interval}min/Time_slots_State_Change/results_{slot}_almostFull_{num_tot_pat}match_{time_interval}min_{window_width}_({conf_threshold}%-{sup_threshold}).txt'\n",
    "    else:\n",
    "        pattern_path = f\"./Results_extraction/{time_interval}min_{space_interval}m/Time_slots/filtered_results_{slot}_({conf_threshold}%-{sup_threshold})_StateChange_Normal_almostFull_{time_interval}_{space_interval}_0(3-3)_ordered_by_confidence.txt\"\n",
    "        output_path = f'Test_results/{time_interval}min/Time_slots_State_Change/results_{slot}_Normal_almostFull_{num_tot_pat}match_{time_interval}min_{window_width}_({conf_threshold}%-{sup_threshold}).txt'\n",
    "\n",
    "    file = open(output_path, \"w\")\n",
    "    file.write(f'PATTERN TESING RESULTS:\\n\\n')\n",
    "    tot_fp = 0\n",
    "    tot_tp = 0\n",
    "    tot_fn = 0\n",
    "    tot_tn = 0\n",
    "\n",
    "\n",
    "    for station_id in SFancisco_stations:\n",
    "\n",
    "        test_path = Path(f'../Traditional_classification/datasets/{time_interval}_{window_width}/Train_test_with_time/station{station_id}_test.csv')\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        time_slot_test_df = test_df.set_index(\"time\", drop=True)\n",
    "        time_slot_test_df.index=pd.to_datetime(time_slot_test_df.index)\n",
    "        start_time= slot.split('-')[0]\n",
    "        end_time = slot.split('-')[1]\n",
    "        if end_time != '24':       \n",
    "            time_slot_test_df = time_slot_test_df.between_time(f'{start_time}:00', f'{end_time}:00')\n",
    "        else:\n",
    "            time_slot_test_df = time_slot_test_df.between_time(f'{start_time}:00', '23:59')\n",
    "\n",
    "        y_test = time_slot_test_df[\"status\"]\n",
    "        y_pred = []\n",
    "        \n",
    "\n",
    "        #itero le righe del test set\n",
    "        for index, row in time_slot_test_df.iterrows():\n",
    "        \n",
    "            num_row=0\n",
    "            num_pat_matched = 0\n",
    "            #print(row['docks_av_41_T4'], row['status'])\n",
    "            prediction = \"N\"\n",
    "\n",
    "            #apro il file ed itero su tutti i pattern\n",
    "            with open(pattern_path, \"r\") as ifile:\n",
    "                for line in ifile:\n",
    "                    num_row+=1\n",
    "                    #elimino gli header del file\n",
    "                    if \"[[[\" not in line:\n",
    "                        continue\n",
    "\n",
    "                    flag = '' # sarà usaro per la condizione di uscita se una regola non metcha\n",
    "\n",
    "                    #Trasformo la linea testuale in una lista\n",
    "                    line_list = ast.literal_eval(line)\n",
    "\n",
    "#                     #Prelevo il conseguente\n",
    "#                     last = line_list[0][0][-1]\n",
    "\n",
    "                    #elimino il conseguente\n",
    "                    prior = line_list[0][0][:-1]\n",
    "\n",
    "                    #Prelevo l'ultimo elemento\n",
    "                    last = prior[-1]\n",
    "\n",
    "                    #Ricavo l'istante temporale dell'ultimo slot che corrisponderà all'istante 0 nella tabella del test set\n",
    "                    curr_time_slot = int(last[0].split('_')[1][1])\n",
    "\n",
    "                    #Itero gli slot di tempo presenti nell'antecedente\n",
    "                    for item in prior:\n",
    "        #                 print(f\"1_{flag}\")\n",
    "\n",
    "                        matched_neigh = 0\n",
    "\n",
    "                        #controllo se è già stata settata la condizione di uscita\n",
    "                        if flag == \"next_line\":\n",
    "                            break\n",
    "\n",
    "                        #ricavo la stringa contenuta nell'i-esimo slot e la splitto per ottenere la lista dei controlli da fare\n",
    "                        check_list = item[0].split(\",\")\n",
    "\n",
    "                        #itero sulla lista contenuta nello stesso slot temporale\n",
    "                        for el in check_list:\n",
    "        #                     print(f\"2_{flag}\")\n",
    "                            #controllo se è già stato settata la condizione di uscita\n",
    "                            if flag == \"next_line\":\n",
    "                                break\n",
    "\n",
    "                            el_status = el.split('_')[0]\n",
    "                            el_time_slot = int(el.split('_')[1][1])\n",
    "                            el_space_slot = int(el.split('_')[2])     \n",
    "\n",
    "                            feature_time_slot = curr_time_slot - el_time_slot\n",
    "\n",
    "                            #se la stazione è quella di riferimento\n",
    "                            if el_space_slot == 0:\n",
    "\n",
    "                                #A partire da queste info costruisco la feature da andare a controllare\n",
    "                                feature_str = f\"docks_av_{station_id}_T{feature_time_slot}\"\n",
    "                                pevious_feature_str = f\"docks_av_{station_id}_T{feature_time_slot + 1}\"\n",
    "\n",
    "        #                         print(feature_str)\n",
    "\n",
    "                                #Se la regola non è verificata, passo alla prossima\n",
    "                                if ((el_status == \"QuasiPiena\" and row[feature_str] > 2)\n",
    "                                    or (el_status == \"Normal\" and row[feature_str] <= 2)\n",
    "                                    #con queste 2 condizioni valuto se c'è stato un cambio di stato\n",
    "                                    or (el_status == \"QuasiPiena\" and row[pevious_feature_str] <= 2)\n",
    "                                    or (el_status == \"Normal\" and row[pevious_feature_str] > 2)\n",
    "                                   ):\n",
    "                                    flag = \"next_line\"\n",
    "        #                             print(f\"3_{flag}\")\n",
    "                                    break\n",
    "\n",
    "\n",
    "                            #se invece si tratta di una delle stazioni vicine:\n",
    "                            else:\n",
    "                                neighbors = distance_dictionary[station_id][el_space_slot-1]\n",
    "                                for neigh_id in neighbors:\n",
    "                                    #inizialmente lo setto al caso negativo\n",
    "                                    flag = \"next_line\"\n",
    "\n",
    "                                    #se il vicino corrente ha già verificato la regola, passo al vicino successivo \n",
    "                                    # (utile nei casi in cui si hanno piu regole nello stesso delta spaziale)\n",
    "                                    if neigh_id == matched_neigh:\n",
    "                                        continue\n",
    "\n",
    "                                    feature_str = f\"docks_av_{neigh_id}_T{feature_time_slot}\"\n",
    "        #                             print(feature_str)\n",
    "\n",
    "                                    #se il vicino corrente non rispetta il pattern, passo al vicino successivo\n",
    "                                    if ((el_status == \"QuasiPiena\" and row[feature_str] > 2) \n",
    "                                        or (el_status == \"Normal\" and row[feature_str] <= 2)\n",
    "                                        #con queste condizioni valuto se c'è stato un cambio di stato \n",
    "                                        or (el_status == \"QuasiPiena\" and row[pevious_feature_str] <= 2)\n",
    "                                        or (el_status == \"Normal\" and row[pevious_feature_str] > 2)\n",
    "                                       ):\n",
    "                                        continue\n",
    "\n",
    "                                    #se invece viene trovato un vicino che rispetta il pattern, rimetto il flag ='' ed esco dal ciclo  \n",
    "                                    flag=''\n",
    "                                    matched_neigh= neigh_id\n",
    "                                    break\n",
    "\n",
    "                                if flag == \"next_line\":\n",
    "                                    break\n",
    "\n",
    "\n",
    "                    #se a questo punto il flag non è stato settato a \"next_line\", vuol dire che nessuna delle condizioni sfavorevoli \n",
    "                    # precedenti è stata verificata, quindi il pattern ha metchato. \n",
    "                    if flag != \"next_line\":\n",
    "                        #incremento il numero di pattern verificati\n",
    "                        num_pat_matched +=1\n",
    "\n",
    "                        #se i numero di pattern verificati è uguale al numero di pattern da verificare desiderato\n",
    "                        if num_pat_matched == num_tot_pat: \n",
    "                            \n",
    "                            # Setto pred a \"QP\" ed esco\n",
    "                            prediction = \"QP\"\n",
    "            #                 print(f'PATTERN MATCHED NUM: {num_row}')\n",
    "                            break\n",
    "\n",
    "            y_pred.append(prediction)\n",
    "\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[\"N\", \"QP\"])\n",
    "\n",
    "        str_= f'PATTERN TEST FOR STATION {station_id}' + '\\n'\n",
    "        str_ += f'Confusion matrix:' + '\\n'\n",
    "        str_ += str(cm) + '\\n'\n",
    "\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        str_+= f'tp={tp}, fn={fn}, fp={fp}, tn={tn}' +'\\n'\n",
    "\n",
    "        test_accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "        #test_recall = (tp) / (tp + fn)\n",
    "        #test_precision = (tp) / (tp + fp)\n",
    "        test_recall = recall_score(y_test, y_pred, pos_label='QP', zero_division=0)\n",
    "        test_precision = precision_score(y_test, y_pred, pos_label='QP', zero_division=0)\n",
    "        test_f1_score = f1_score(y_test, y_pred, pos_label='QP', zero_division=0)\n",
    "\n",
    "        str_+= f'accuracy={test_accuracy}; recall={test_recall}; precision={test_precision}; f1_score= {test_f1_score}' +'\\n\\n'\n",
    "        str_+= \"-\"*10 +'\\n\\n'\n",
    "\n",
    "        tot_fp += fp\n",
    "        tot_tp += tp\n",
    "        tot_fn += fn\n",
    "        tot_tn += tn\n",
    "\n",
    "        file.write(str_)\n",
    "#         print(str_)\n",
    "\n",
    "    avg_accuracy = (tot_tn + tot_tp) / (tot_tn + tot_fp + tot_fn + tot_tp)\n",
    "    avg_recall = (tot_tp) / (tot_tp + tot_fn)\n",
    "    if (tot_tp + tot_fp) != 0.0:\n",
    "        avg_precision = (tot_tp) / (tot_tp + tot_fp)\n",
    "    else:\n",
    "        avg_precision = 0.0\n",
    "    \n",
    "    if avg_recall!= 0.0 and avg_precision!= 0.0:\n",
    "        avg_f1_score = 2*(1/((1/avg_recall)+(1/avg_precision)))\n",
    "    else:\n",
    "        avg_f1_score = 0.0\n",
    "\n",
    "    avg_str = \"AVERAGE VALUES FOR PATTERN TEST:\\n\"\n",
    "    avg_str += \"Confusion matrix:\\n\"\n",
    "    avg_str += f\"[[{tot_tn} {tot_fp}]\\n[{tot_fn} {tot_tp}]]\\n\"\n",
    "    avg_str += f\"tot_tp={tot_tp}, tot_fn={tot_fn}, tot_fp={tot_fp}, tot_tn={tot_tn}\\n\"\n",
    "    avg_str += f\"accuracy={avg_accuracy}; recall={avg_recall}; precision={avg_precision}; f1_score={avg_f1_score}\\n\\n\"\n",
    "    print(avg_str)\n",
    "    file.write(avg_str)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-mineral",
   "metadata": {},
   "source": [
    "#### Tabella contenente tutti i risultati considerando un intervallo di 30 minuti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assigned-armstrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50%_0-6_1match</th>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.7169</td>\n",
       "      <td>0.0629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50%_6-10_1match</th>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.6242</td>\n",
       "      <td>0.1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50%_10-14_1match</th>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.1718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50%_14-17_1match</th>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.0329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50%_17-20_20match</th>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50%_20-24_15match</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>0.0204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            avg_recall  avg_precision  avg_f1_score\n",
       "N/QP_conf50%_0-6_1match         0.0329         0.7169        0.0629\n",
       "N/QP_conf50%_6-10_1match        0.0584         0.6242        0.1068\n",
       "N/QP_conf50%_10-14_1match       0.0972         0.7368        0.1718\n",
       "N/QP_conf50%_14-17_1match       0.0168         0.7083        0.0329\n",
       "N/QP_conf50%_17-20_20match      0.0015         0.6667        0.0029\n",
       "N/QP_conf50%_20-24_15match      0.0103         0.8261        0.0204"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_filter_normal = False\n",
    "\n",
    "if current_filter_normal:\n",
    "    time_slots_dict ={\n",
    "    \"0-6\" : [1, 15, 18, 20, 25],     # 22 pattern totali\n",
    "#     \"6-10\" : [1, 15, 18, 20, 25],    # 20 pattern totali\n",
    "#     \"10-14\" : [1, 15, 20, 25, 30],     # 41 pattern totali\n",
    "#     \"14-17\" : [1, 15, 20, 25, 30],     # 32 pattern totali\n",
    "#     \"17-20\" : [1, 15, 20, 25, 30],     # 45 pattern totali\n",
    "#     \"20-24\" : [1, 15, 18, 20, 25]    # 21 pattern totali\n",
    "    }\n",
    "    best_results ={\n",
    "        \"0-6\" : [18],     # 22 pattern totali\n",
    "        \"6-10\" : [15],    # 20 pattern totali\n",
    "        \"10-14\" : [25],     # 41 pattern totali\n",
    "        \"14-17\" : [25],     # 32 pattern totali\n",
    "        \"17-20\" : [30],     # 45 pattern totali\n",
    "        \"20-24\" : [15]    # 21 pattern totali\n",
    "    }\n",
    "    \n",
    "else: \n",
    "    best_results ={\n",
    "        \"0-6\" : [1],     \n",
    "        \"6-10\" : [1],    \n",
    "        \"10-14\" : [1],     \n",
    "        \"14-17\" : [1],     \n",
    "        \"17-20\" : [20],     \n",
    "        \"20-24\" : [15]    \n",
    "    }\n",
    "    time_slots_dict ={\n",
    "    \"0-6\" : [1, 15, 18, 20, 25],     # 22 pattern totali\n",
    "    \"6-10\" : [1, 15, 18, 20, 25],    # 20 pattern totali\n",
    "    \"10-14\" : [1, 15, 20, 25, 30],     # 41 pattern totali\n",
    "    \"14-17\" : [1, 15, 20, 25, 30],     # 32 pattern totali\n",
    "    \"17-20\" : [1, 15, 20, 25, 30],     # 45 pattern totali\n",
    "    \"20-24\" : [1, 15, 18, 20, 25]    # 21 pattern totali\n",
    "    }\n",
    "    \n",
    "    \n",
    "# selezionare il numero di patern, la soglia di confidenza e la soglia di supporto desiderati per stampare tutti \n",
    "# i risultati ottenuti per le diverse fasce\n",
    "current_conf_threshold = 50\n",
    "current_sup_threshold = 0\n",
    "num_pattern_list = [15] \n",
    "\n",
    "rows = []\n",
    "result_matrix = []\n",
    "columns = [\"avg_accuracy\", \"avg_recall\", \"avg_precision\", \"avg_f1_score\"]\n",
    "\n",
    "for slot in time_slots_dict.keys():\n",
    "#     for num_pat in num_pattern_list:\n",
    "    for num_pat in best_results[slot]:\n",
    "        if current_filter_normal:\n",
    "            status_str= \"QP\"\n",
    "            input_file_name = f\"results_{slot}_almostFull_{num_pat}match_{time_interval}min_{window_width}_({current_conf_threshold}%-{current_sup_threshold}).txt\"\n",
    "        else:\n",
    "            status_str= \"N/QP\"\n",
    "            input_file_name = f\"results_{slot}_Normal_almostFull_{num_pat}match_{time_interval}min_{window_width}_({current_conf_threshold}%-{current_sup_threshold}).txt\"\n",
    "        \n",
    "        input_file_path = f\"Test_results/{time_interval}min/Time_slots_State_Change/{input_file_name}\"\n",
    "\n",
    "        row = f\"{status_str}_conf{current_conf_threshold}%_{slot}_{num_pat}match\"\n",
    "        rows.append(row)\n",
    "        with open(input_file_path, \"r\") as file:\n",
    "            lines = file.read().splitlines()\n",
    "            last_line = lines[-2]\n",
    "#             print (last_line)\n",
    "            results = last_line.split(';')\n",
    "            result_values = []\n",
    "            for result in results:\n",
    "#                 print (result)\n",
    "                value = round(float(result.split('=')[1]), 4)\n",
    "                result_values.append(value)\n",
    "            result_matrix.append(result_values)\n",
    "\n",
    "results_table = pd.DataFrame(result_matrix, columns=columns, index=pd.Index(rows))\n",
    "# print(results_table.to_latex(float_format=\"%.4f\", bold_rows=True))\n",
    "results_table = results_table.drop(columns=[\"avg_accuracy\"])\n",
    "results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-controversy",
   "metadata": {},
   "source": [
    "#### Valuto le prestazioni generali del modello, considerando alcuni valori di default per il numero minimo di pattern. In questo modo possiamo vedere come si comporta generalmente il modello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-builder",
   "metadata": {},
   "source": [
    "Vado quindi a ricavare e sommare le varie matrici di confusione iterando sulle diverse fasce orarie, per i diversi valori di default per il numero minimo di pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "latest-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMERO MINIMO DI PATTERN:1\n",
      "[[304397 500]\n",
      "[10150 933]]\n",
      "all_tp=933, all_fn=10150, all_fp=500, all_tn=304397\n",
      "accuracy=0.9663; recall=0.08418; precision=0.65108; f1_score=0.14908\n",
      "\n",
      "\n",
      "NUMERO MINIMO DI PATTERN:15\n",
      "[[304876 21]\n",
      "[11042 41]]\n",
      "all_tp=41, all_fn=11042, all_fp=21, all_tn=304876\n",
      "accuracy=0.96499; recall=0.0037; precision=0.66129; f1_score=0.00736\n",
      "\n",
      "\n",
      "NUMERO MINIMO DI PATTERN:18\n",
      "[[304883 14]\n",
      "[11056 27]]\n",
      "all_tp=27, all_fn=11056, all_fp=14, all_tn=304883\n",
      "accuracy=0.96497; recall=0.00244; precision=0.65854; f1_score=0.00486\n",
      "\n",
      "\n",
      "NUMERO MINIMO DI PATTERN:20\n",
      "[[304885 12]\n",
      "[11059 24]]\n",
      "all_tp=24, all_fn=11059, all_fp=12, all_tn=304885\n",
      "accuracy=0.96496; recall=0.00217; precision=0.66667; f1_score=0.00433\n",
      "\n",
      "\n",
      "NUMERO MINIMO DI PATTERN:25\n",
      "[[304889 8]\n",
      "[11074 9]]\n",
      "all_tp=9, all_fn=11074, all_fp=8, all_tn=304889\n",
      "accuracy=0.96493; recall=0.00081; precision=0.52941; f1_score=0.00162\n",
      "\n",
      "\n",
      "NUMERO MINIMO DI PATTERN:30\n",
      "[[304890 7]\n",
      "[11076 7]]\n",
      "all_tp=7, all_fn=11076, all_fp=7, all_tn=304890\n",
      "accuracy=0.96492; recall=0.00063; precision=0.5; f1_score=0.00126\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oa_recall</th>\n",
       "      <th>oa_precision</th>\n",
       "      <th>oa_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50_1match</th>\n",
       "      <td>0.08418</td>\n",
       "      <td>0.65108</td>\n",
       "      <td>0.14908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50_15match</th>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.66129</td>\n",
       "      <td>0.00736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50_18match</th>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.65854</td>\n",
       "      <td>0.00486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50_20match</th>\n",
       "      <td>0.00217</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.00433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50_25match</th>\n",
       "      <td>0.00081</td>\n",
       "      <td>0.52941</td>\n",
       "      <td>0.00162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/QP_conf50_30match</th>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     oa_recall  oa_precision  oa_f1_score\n",
       "N/QP_conf50_1match     0.08418       0.65108      0.14908\n",
       "N/QP_conf50_15match    0.00370       0.66129      0.00736\n",
       "N/QP_conf50_18match    0.00244       0.65854      0.00486\n",
       "N/QP_conf50_20match    0.00217       0.66667      0.00433\n",
       "N/QP_conf50_25match    0.00081       0.52941      0.00162\n",
       "N/QP_conf50_30match    0.00063       0.50000      0.00126"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_filter_normal = False\n",
    "current_conf_threshold = 50\n",
    "current_sup_threshold = 0\n",
    "\n",
    "\n",
    "total_conf_matrix = {}\n",
    "result_matrix = []\n",
    "default_num_pat =[1, 15, 18, 20, 25, 30] \n",
    "rows = []\n",
    "\n",
    "for num_pat in default_num_pat: \n",
    "    print(f\"NUMERO MINIMO DI PATTERN:{num_pat}\")\n",
    "    if current_filter_normal:\n",
    "        rows.append(f\"QP_conf{current_conf_threshold}_{num_pat}match\")\n",
    "        status= \"almostFull\"\n",
    "    else:\n",
    "        rows.append(f\"N/QP_conf{current_conf_threshold}_{num_pat}match\")\n",
    "        status = \"Normal_almostFull\"\n",
    "    all_fp=0\n",
    "    all_tp=0\n",
    "    all_fn=0\n",
    "    all_tn=0\n",
    "        \n",
    "    for slot in time_slots:\n",
    "        input_file_name = f\"results_{slot}_{status}_{num_pat}match_{time_interval}min_{window_width}_({current_conf_threshold}%-{current_sup_threshold}).txt\"\n",
    "        input_file_path = f\"Test_results/{time_interval}min/Time_slots_State_Change/{input_file_name}\"\n",
    "        \n",
    "        with open(input_file_path, \"r\") as file:\n",
    "            lines = file.read().splitlines()\n",
    "            last_line = lines[-3]\n",
    "#             print (last_line)\n",
    "            results = last_line.split(', ')\n",
    "            result_values = []\n",
    "            for result in results:\n",
    "#                 print (result)\n",
    "                value = int(result.split('=')[1])\n",
    "                result_values.append(value)\n",
    "        all_tp+=result_values[0]   \n",
    "        all_fn+=result_values[1]\n",
    "        all_fp+=result_values[2]\n",
    "        all_tn+=result_values[3]\n",
    "        \n",
    "    avg_accuracy = round((all_tn + all_tp) / (all_tn + all_fp + all_fn + all_tp), 5)\n",
    "    avg_recall = round((all_tp) / (all_tp + all_fn), 5)\n",
    "    if (all_tp + all_fp) != 0.0:\n",
    "        avg_precision = round((all_tp) / (all_tp + all_fp), 5)\n",
    "    else:\n",
    "        avg_precision = 0.0\n",
    "\n",
    "    if avg_recall!= 0.0 and avg_precision!= 0.0:\n",
    "        avg_f1_score = round(2*(1/((1/avg_recall)+(1/avg_precision))), 5)\n",
    "    else:\n",
    "        avg_f1_score = 0.0\n",
    "\n",
    "#     result_matrix.append([avg_accuracy, avg_recall, avg_precision, avg_f1_score])\n",
    "    result_matrix.append([avg_recall, avg_precision, avg_f1_score])\n",
    "    final_str = f\"[[{all_tn} {all_fp}]\\n[{all_fn} {all_tp}]]\\n\"\n",
    "    final_str += f\"all_tp={all_tp}, all_fn={all_fn}, all_fp={all_fp}, all_tn={all_tn}\\n\"\n",
    "    final_str += f\"accuracy={avg_accuracy}; recall={avg_recall}; precision={avg_precision}; f1_score={avg_f1_score}\\n\\n\"\n",
    "    print (final_str)\n",
    "    total_conf_matrix[num_pat] = [all_tp, all_fn, all_fp, all_tn]\n",
    "\n",
    "# result_table = pd.DataFrame(result_matrix, columns=['avg_accuracy', 'avg_recall', 'avg_precision', 'avg_f1_score'], index=pd.Index(rows))\n",
    "result_table = pd.DataFrame(result_matrix, columns=['oa_recall', 'oa_precision', 'oa_f1_score'], index=pd.Index(rows))\n",
    "result_table.to_csv(f\"./Test_results/{time_interval}min/Time_slots/Overall_results_AllSlots_{status}_conf{current_conf_threshold}_sup{current_sup_threshold}.csv\")\n",
    "result_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
